{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1363ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '/data3/gkook/model/Qwen2-Audio-7B-Instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63931043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "import random\n",
    "import librosa\n",
    "from transformers import AutoProcessor, Qwen2AudioForConditionalGeneration, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "# --- 0. 환경 변수 설정 ---\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "os.environ[\"HF_HOME\"] = \"/data1/jc/AGI\"\n",
    "\n",
    "# Set the base output directory for all saves\n",
    "BASE_OUTPUT_DIR = \"/data1/jc/AGI/LibriSpeech/LibriSpeech/train/LibriSpeech/\"\n",
    "os.makedirs(BASE_OUTPUT_DIR, exist_ok=True) # Ensure the directory exists\n",
    "\n",
    "# W&B API 키 및 프로젝트 이름 설정\n",
    "os.environ[\"WANDB_API_KEY\"] = \"ed10e1d235ad82c9e6a4dc4dbc622488d71c8ef6\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"qwen2-audio-finetune\" # This remains the W&B project name\n",
    "os.environ[\"WANDB_DIR\"] = BASE_OUTPUT_DIR # Set WANDB_DIR to control where W&B files are stored\n",
    "print(f\"WandB directory set to: {os.environ['WANDB_DIR']}\")\n",
    "\n",
    "print(\"환경 설정 완료.\")\n",
    "\n",
    "# --- 1. 모델 및 프로세서 로드 ---\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"사용할 디바이스: {device}\")\n",
    "\n",
    "try:\n",
    "    print(f\"Loading Qwen2-Audio-7B-Instruct processor...\")\n",
    "    processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\", trust_remote_code=True)\n",
    "    \n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,\n",
    "    )\n",
    "    \n",
    "    print(f\"Loading Qwen2-Audio-7B-Instruct model with 4-bit quantization...\")\n",
    "    model = Qwen2AudioForConditionalGeneration.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    print(\"Qwen2-Audio-7B-Instruct 모델 및 프로세서 로드 완료.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n[오류 발생] 모델 로드 중 오류: {e}\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a90314",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717f9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_trainable_param = 0\n",
    "for n , p in model.named_parameters():\n",
    "    if p.requires_grad==True:\n",
    "        print('trainable', n, p.numel())\n",
    "        print_trainable_param += p.numel()\n",
    "    else:\n",
    "        print('not trainable', n, p.numel())\n",
    "print(f\"Trainable parameters: {print_trainable_param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9414cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def count_trainable_parameters(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params\n",
    "\n",
    "count_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5f425",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a66b49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'iknow-lab/BridgeDataV2-audio' 데이터셋 로드 중... (시간이 걸릴 수 있습니다)\n",
      "데이터셋의 각 split에서 오디오 길이 계산 중...\n",
      "--- train split 처리 중 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train split 진행률:   0%|          | 10/21676 [00:00<03:48, 94.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[디버깅] 첫 번째 예제의 audio_data 타입: <class 'datasets.features._torchcodec.AudioDecoder'>\n",
      "[디버깅] metadata 타입: <class 'torchcodec._core._metadata.AudioStreamMetadata'>\n",
      "[디버깅] metadata 속성들: ['__annotations__', '__class__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'begin_stream_seconds_from_header', 'bit_rate', 'codec', 'duration_seconds_from_header', 'num_channels', 'path', 'sample_format', 'sample_rate', 'stream_index']\n",
      "[디버깅] metadata.__dict__: {'duration_seconds_from_header': 1.591293, 'begin_stream_seconds_from_header': None, 'bit_rate': 352800.0, 'codec': 'pcm_s16le', 'stream_index': 0, 'sample_rate': 22050, 'num_channels': 1, 'sample_format': 's16', 'path': '0.wav'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train split 진행률: 100%|██████████| 21676/21676 [02:23<00:00, 150.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "'iknow-lab/BridgeDataV2-audio' 데이터셋의 총 오디오 길이 (유효한 파일 기준):\n",
      "==> 17시간 5분 28초\n",
      "(총 61528.57 초)\n",
      "\n",
      "총 0개의 오디오 파일 처리 중 오류가 발생하여 건너뛰었습니다.\n",
      "==============================\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "def calculate_total_duration(dataset_name):\n",
    "    \"\"\"\n",
    "    Hugging Face 데이터셋의 모든 오디오 파일 총 길이를 계산합니다.\n",
    "    오류가 발생하는 파일은 건너뛰고 횟수를 셉니다.\n",
    "    \"\"\"\n",
    "    print(f\"'{dataset_name}' 데이터셋 로드 중... (시간이 걸릴 수 있습니다)\")\n",
    "    \n",
    "    try:\n",
    "        dataset = datasets.load_dataset(dataset_name)\n",
    "    except Exception as e:\n",
    "        print(f\"데이터셋 로드 중 오류 발생: {e}\")\n",
    "        return None, 0\n",
    "\n",
    "    total_seconds = 0.0\n",
    "    error_count = 0\n",
    "    \n",
    "    print(\"데이터셋의 각 split에서 오디오 길이 계산 중...\")\n",
    "\n",
    "    for split_name in dataset.keys():\n",
    "        print(f\"--- {split_name} split 처리 중 ---\")\n",
    "        \n",
    "        split_dataset = dataset[split_name]\n",
    "        \n",
    "        # 첫 번째 예제로 metadata 구조 확인 (디버깅용)\n",
    "        debug_checked = False\n",
    "        \n",
    "        # tqdm을 사용하여 진행 상황 표시\n",
    "        for idx, example in enumerate(tqdm(split_dataset, desc=f\"{split_name} split 진행률\")):\n",
    "            try:\n",
    "                # 오디오 키가 있는지 확인\n",
    "                if \"audio\" not in example:\n",
    "                    error_count += 1\n",
    "                    continue\n",
    "                \n",
    "                # 오디오 데이터 접근 시도 (디코딩 오류가 여기서 발생할 수 있음)\n",
    "                audio_data = example.get(\"audio\")\n",
    "                if audio_data is None:\n",
    "                    error_count += 1\n",
    "                    continue\n",
    "                \n",
    "                # 첫 번째 예제의 metadata 구조 확인 (디버깅용)\n",
    "                if not debug_checked and not isinstance(audio_data, dict) and hasattr(audio_data, 'metadata'):\n",
    "                    print(f\"\\n[디버깅] 첫 번째 예제의 audio_data 타입: {type(audio_data)}\")\n",
    "                    print(f\"[디버깅] metadata 타입: {type(audio_data.metadata)}\")\n",
    "                    if audio_data.metadata is not None:\n",
    "                        if isinstance(audio_data.metadata, dict):\n",
    "                            print(f\"[디버깅] metadata (dict): {audio_data.metadata}\")\n",
    "                        else:\n",
    "                            print(f\"[디버깅] metadata 속성들: {dir(audio_data.metadata)}\")\n",
    "                            if hasattr(audio_data.metadata, '__dict__'):\n",
    "                                print(f\"[디버깅] metadata.__dict__: {audio_data.metadata.__dict__}\")\n",
    "                    debug_checked = True\n",
    "                \n",
    "                # audio_data가 딕셔너리인지 확인\n",
    "                if isinstance(audio_data, dict):\n",
    "                    # 일반 딕셔너리 형태인 경우\n",
    "                    if \"array\" not in audio_data or \"sampling_rate\" not in audio_data:\n",
    "                        error_count += 1\n",
    "                        continue\n",
    "                    \n",
    "                    num_samples = len(audio_data[\"array\"])\n",
    "                    sampling_rate = audio_data[\"sampling_rate\"]\n",
    "                    \n",
    "                    if sampling_rate > 0 and num_samples > 0:\n",
    "                        duration = num_samples / sampling_rate\n",
    "                        total_seconds += duration\n",
    "                    else:\n",
    "                        error_count += 1\n",
    "                else:\n",
    "                    # AudioDecoder 객체인 경우 (datasets.features._torchcodec.AudioDecoder)\n",
    "                    duration = None\n",
    "                    sampling_rate = None\n",
    "                    \n",
    "                    # 0. AudioDecoder를 딕셔너리처럼 접근 시도 (일부 구현에서는 가능)\n",
    "                    try:\n",
    "                        if hasattr(audio_data, '__getitem__'):\n",
    "                            # 'duration' 키로 직접 접근 시도\n",
    "                            try:\n",
    "                                duration = audio_data['duration']\n",
    "                            except (KeyError, TypeError):\n",
    "                                pass\n",
    "                            # 'sampling_rate' 또는 'sample_rate' 키로 접근 시도\n",
    "                            try:\n",
    "                                sampling_rate = audio_data.get('sampling_rate') or audio_data.get('sample_rate')\n",
    "                            except (AttributeError, TypeError):\n",
    "                                pass\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    # 1. metadata에서 duration 정보 확인 (가장 빠름, 디코딩 불필요)\n",
    "                    if duration is None and hasattr(audio_data, 'metadata') and audio_data.metadata is not None:\n",
    "                        metadata = audio_data.metadata\n",
    "                        # metadata가 딕셔너리인 경우\n",
    "                        if isinstance(metadata, dict):\n",
    "                            duration = metadata.get('duration')\n",
    "                            sampling_rate = metadata.get('sample_rate') or metadata.get('sampling_rate')\n",
    "                        # metadata가 객체인 경우 - 다양한 속성명 시도\n",
    "                        else:\n",
    "                            # duration 속성 시도 (torchcodec의 AudioStreamMetadata는 duration_seconds_from_header 사용)\n",
    "                            duration = getattr(metadata, 'duration_seconds_from_header', None)\n",
    "                            if duration is None:\n",
    "                                duration = getattr(metadata, 'duration', None)\n",
    "                            if duration is None:\n",
    "                                # 다른 가능한 속성명들 시도\n",
    "                                duration = getattr(metadata, 'length', None)\n",
    "                                duration = getattr(metadata, 'duration_seconds', None) if duration is None else duration\n",
    "                            \n",
    "                            # sampling_rate 속성 시도 (torchcodec의 AudioStreamMetadata는 sample_rate 사용)\n",
    "                            sampling_rate = getattr(metadata, 'sample_rate', None)\n",
    "                            if sampling_rate is None:\n",
    "                                sampling_rate = getattr(metadata, 'sampling_rate', None)\n",
    "                            if sampling_rate is None:\n",
    "                                sampling_rate = getattr(metadata, 'sr', None)\n",
    "                    \n",
    "                    # metadata가 없거나 duration을 못 찾은 경우, __dict__에서 직접 확인\n",
    "                    if duration is None and hasattr(audio_data, 'metadata'):\n",
    "                        # metadata를 dict로 변환 시도 (torchcodec의 AudioStreamMetadata는 __dict__에 duration_seconds_from_header가 있음)\n",
    "                        try:\n",
    "                            if hasattr(audio_data.metadata, '__dict__'):\n",
    "                                metadata_dict = audio_data.metadata.__dict__\n",
    "                                duration = metadata_dict.get('duration_seconds_from_header') or metadata_dict.get('duration') or metadata_dict.get('length')\n",
    "                                sampling_rate = metadata_dict.get('sample_rate') or metadata_dict.get('sampling_rate') or metadata_dict.get('sr')\n",
    "                        except:\n",
    "                            pass\n",
    "                    \n",
    "                    # 2. duration이 있으면 바로 사용\n",
    "                    if duration is not None and duration > 0:\n",
    "                        total_seconds += duration\n",
    "                        continue\n",
    "                    \n",
    "                    # 3. duration이 없으면 sampling_rate 확인 후 get_all_samples()로 계산\n",
    "                    if not sampling_rate:\n",
    "                        # _desired_sample_rate에서 가져오기\n",
    "                        if hasattr(audio_data, '_desired_sample_rate') and audio_data._desired_sample_rate:\n",
    "                            sampling_rate = audio_data._desired_sample_rate\n",
    "                    \n",
    "                    # 4. get_all_samples()로 샘플 수 계산 (FFmpeg 디코딩 오류 발생 가능)\n",
    "                    if sampling_rate:\n",
    "                        try:\n",
    "                            samples = audio_data.get_all_samples()\n",
    "                            # samples가 torch tensor인 경우\n",
    "                            if hasattr(samples, 'data'):\n",
    "                                num_samples = samples.data.shape[-1] if len(samples.data.shape) > 0 else len(samples.data)\n",
    "                            # samples가 numpy array인 경우\n",
    "                            elif hasattr(samples, 'shape'):\n",
    "                                num_samples = samples.shape[-1] if len(samples.shape) > 0 else len(samples)\n",
    "                            # 일반 리스트나 배열인 경우\n",
    "                            else:\n",
    "                                num_samples = len(samples) if hasattr(samples, '__len__') else 0\n",
    "                            \n",
    "                            if num_samples > 0 and sampling_rate > 0:\n",
    "                                duration = num_samples / sampling_rate\n",
    "                                total_seconds += duration\n",
    "                            else:\n",
    "                                error_count += 1\n",
    "                        except Exception:\n",
    "                            # get_all_samples() 호출 시 에러 발생 (FFmpeg 디코딩 오류 등)\n",
    "                            error_count += 1\n",
    "                    else:\n",
    "                        # sampling_rate도 없으면 에러\n",
    "                        error_count += 1\n",
    "                \n",
    "            except (RuntimeError, KeyError, TypeError, AttributeError, ValueError) as e:\n",
    "                # 'The frame has 0 channels' 같은 모든 디코딩 오류를 여기서 처리\n",
    "                error_count += 1\n",
    "                # 디버깅을 위해 가끔 에러 메시지 출력 (너무 많이 출력되지 않도록)\n",
    "                if error_count <= 5 or error_count % 1000 == 0:\n",
    "                    print(f\"\\n[경고] 오디오 처리 오류 (누적 {error_count}개): {type(e).__name__}\")\n",
    "            except Exception as e:\n",
    "                # 예상치 못한 다른 에러들\n",
    "                error_count += 1\n",
    "                if error_count <= 5:\n",
    "                    print(f\"\\n[경고] 예상치 못한 오류 (누적 {error_count}개): {type(e).__name__}: {str(e)[:100]}\")\n",
    "\n",
    "    return total_seconds, error_count\n",
    "\n",
    "def format_duration(total_seconds):\n",
    "    \"\"\"\n",
    "    총 초를 (시, 분, 초) 형식으로 변환합니다.\n",
    "    \"\"\"\n",
    "    total_seconds = math.floor(total_seconds)\n",
    "    hours = total_seconds // 3600\n",
    "    minutes = (total_seconds % 3600) // 60\n",
    "    seconds = total_seconds % 60\n",
    "    return hours, minutes, seconds\n",
    "\n",
    "# --- 메인 코드 실행 ---\n",
    "dataset_id = \"iknow-lab/BridgeDataV2-audio\"\n",
    "total_duration_seconds, errors = calculate_total_duration(dataset_id)\n",
    "\n",
    "if total_duration_seconds is not None:\n",
    "    h, m, s = format_duration(total_duration_seconds)\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(f\"'{dataset_id}' 데이터셋의 총 오디오 길이 (유효한 파일 기준):\")\n",
    "    print(f\"==> {h}시간 {m}분 {s}초\")\n",
    "    print(f\"(총 {total_duration_seconds:.2f} 초)\")\n",
    "    print(\"\\n\" + f\"총 {errors}개의 오디오 파일 처리 중 오류가 발생하여 건너뛰었습니다.\")\n",
    "    print(\"=\"*30)\n",
    "    print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcb92f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gkook_agi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
