{
  "best_global_step": 17000,
  "best_metric": 0.8217891454696655,
  "best_model_checkpoint": "/data3/gkook/temp/agi/canary-qwen-2.5b_ft_result_v3/checkpoint-17000",
  "epoch": 2.865599541490973,
  "eval_steps": 500,
  "global_step": 17500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016375322389159536,
      "grad_norm": 1.873152494430542,
      "learning_rate": 1.98e-06,
      "loss": 5.5507,
      "step": 100
    },
    {
      "epoch": 0.03275064477831907,
      "grad_norm": 2.743833303451538,
      "learning_rate": 3.980000000000001e-06,
      "loss": 5.4611,
      "step": 200
    },
    {
      "epoch": 0.04912596716747861,
      "grad_norm": 3.532827615737915,
      "learning_rate": 5.98e-06,
      "loss": 5.0731,
      "step": 300
    },
    {
      "epoch": 0.06550128955663814,
      "grad_norm": 3.24397873878479,
      "learning_rate": 7.980000000000002e-06,
      "loss": 4.2028,
      "step": 400
    },
    {
      "epoch": 0.08187661194579768,
      "grad_norm": 1.9756138324737549,
      "learning_rate": 9.980000000000001e-06,
      "loss": 3.1084,
      "step": 500
    },
    {
      "epoch": 0.08187661194579768,
      "eval_loss": 2.6708481311798096,
      "eval_runtime": 317.2622,
      "eval_samples_per_second": 19.807,
      "eval_steps_per_second": 4.952,
      "step": 500
    },
    {
      "epoch": 0.09825193433495721,
      "grad_norm": 2.2162601947784424,
      "learning_rate": 9.944447561865215e-06,
      "loss": 2.3381,
      "step": 600
    },
    {
      "epoch": 0.11462725672411675,
      "grad_norm": 0.6477717161178589,
      "learning_rate": 9.888333987991696e-06,
      "loss": 1.8208,
      "step": 700
    },
    {
      "epoch": 0.13100257911327629,
      "grad_norm": 2.3006324768066406,
      "learning_rate": 9.832220414118176e-06,
      "loss": 1.6522,
      "step": 800
    },
    {
      "epoch": 0.14737790150243582,
      "grad_norm": 1.8456871509552002,
      "learning_rate": 9.776106840244655e-06,
      "loss": 1.1424,
      "step": 900
    },
    {
      "epoch": 0.16375322389159536,
      "grad_norm": 0.4512876272201538,
      "learning_rate": 9.719993266371136e-06,
      "loss": 0.8445,
      "step": 1000
    },
    {
      "epoch": 0.16375322389159536,
      "eval_loss": 0.8273866176605225,
      "eval_runtime": 317.172,
      "eval_samples_per_second": 19.813,
      "eval_steps_per_second": 4.953,
      "step": 1000
    },
    {
      "epoch": 0.1801285462807549,
      "grad_norm": 0.1488536298274994,
      "learning_rate": 9.663879692497617e-06,
      "loss": 0.8375,
      "step": 1100
    },
    {
      "epoch": 0.19650386866991443,
      "grad_norm": 0.086881123483181,
      "learning_rate": 9.607766118624096e-06,
      "loss": 0.8341,
      "step": 1200
    },
    {
      "epoch": 0.21287919105907396,
      "grad_norm": 0.02740214578807354,
      "learning_rate": 9.551652544750576e-06,
      "loss": 0.8339,
      "step": 1300
    },
    {
      "epoch": 0.2292545134482335,
      "grad_norm": 0.06645907461643219,
      "learning_rate": 9.495538970877057e-06,
      "loss": 0.8288,
      "step": 1400
    },
    {
      "epoch": 0.24562983583739306,
      "grad_norm": 0.05254647880792618,
      "learning_rate": 9.439425397003536e-06,
      "loss": 0.8295,
      "step": 1500
    },
    {
      "epoch": 0.24562983583739306,
      "eval_loss": 0.8228367567062378,
      "eval_runtime": 315.5158,
      "eval_samples_per_second": 19.917,
      "eval_steps_per_second": 4.979,
      "step": 1500
    },
    {
      "epoch": 0.26200515822655257,
      "grad_norm": 0.10058081150054932,
      "learning_rate": 9.383311823130015e-06,
      "loss": 0.8309,
      "step": 1600
    },
    {
      "epoch": 0.27838048061571213,
      "grad_norm": 0.01507855486124754,
      "learning_rate": 9.327198249256496e-06,
      "loss": 0.8286,
      "step": 1700
    },
    {
      "epoch": 0.29475580300487164,
      "grad_norm": 0.022373192012310028,
      "learning_rate": 9.271084675382977e-06,
      "loss": 0.8291,
      "step": 1800
    },
    {
      "epoch": 0.3111311253940312,
      "grad_norm": 0.027734825387597084,
      "learning_rate": 9.214971101509456e-06,
      "loss": 0.8299,
      "step": 1900
    },
    {
      "epoch": 0.3275064477831907,
      "grad_norm": 0.041948217898607254,
      "learning_rate": 9.158857527635936e-06,
      "loss": 0.827,
      "step": 2000
    },
    {
      "epoch": 0.3275064477831907,
      "eval_loss": 0.822253942489624,
      "eval_runtime": 315.4521,
      "eval_samples_per_second": 19.921,
      "eval_steps_per_second": 4.98,
      "step": 2000
    },
    {
      "epoch": 0.3438817701723503,
      "grad_norm": 0.011359102092683315,
      "learning_rate": 9.102743953762417e-06,
      "loss": 0.8304,
      "step": 2100
    },
    {
      "epoch": 0.3602570925615098,
      "grad_norm": 0.0072319405153393745,
      "learning_rate": 9.046630379888896e-06,
      "loss": 0.8315,
      "step": 2200
    },
    {
      "epoch": 0.37663241495066935,
      "grad_norm": 0.02114494889974594,
      "learning_rate": 8.990516806015375e-06,
      "loss": 0.8308,
      "step": 2300
    },
    {
      "epoch": 0.39300773733982886,
      "grad_norm": 0.010529516264796257,
      "learning_rate": 8.934403232141856e-06,
      "loss": 0.8281,
      "step": 2400
    },
    {
      "epoch": 0.4093830597289884,
      "grad_norm": 0.03349868953227997,
      "learning_rate": 8.878289658268336e-06,
      "loss": 0.8287,
      "step": 2500
    },
    {
      "epoch": 0.4093830597289884,
      "eval_loss": 0.8220988512039185,
      "eval_runtime": 315.9816,
      "eval_samples_per_second": 19.887,
      "eval_steps_per_second": 4.972,
      "step": 2500
    },
    {
      "epoch": 0.4257583821181479,
      "grad_norm": 0.04808821156620979,
      "learning_rate": 8.822176084394815e-06,
      "loss": 0.8307,
      "step": 2600
    },
    {
      "epoch": 0.4421337045073075,
      "grad_norm": 0.028478313237428665,
      "learning_rate": 8.766062510521296e-06,
      "loss": 0.8311,
      "step": 2700
    },
    {
      "epoch": 0.458509026896467,
      "grad_norm": 0.011363080702722073,
      "learning_rate": 8.709948936647777e-06,
      "loss": 0.8306,
      "step": 2800
    },
    {
      "epoch": 0.47488434928562656,
      "grad_norm": 0.01314519066363573,
      "learning_rate": 8.653835362774256e-06,
      "loss": 0.8313,
      "step": 2900
    },
    {
      "epoch": 0.4912596716747861,
      "grad_norm": 0.00883838627487421,
      "learning_rate": 8.597721788900735e-06,
      "loss": 0.8313,
      "step": 3000
    },
    {
      "epoch": 0.4912596716747861,
      "eval_loss": 0.8219887018203735,
      "eval_runtime": 316.7978,
      "eval_samples_per_second": 19.836,
      "eval_steps_per_second": 4.959,
      "step": 3000
    },
    {
      "epoch": 0.5076349940639456,
      "grad_norm": 0.1625663787126541,
      "learning_rate": 8.541608215027216e-06,
      "loss": 0.828,
      "step": 3100
    },
    {
      "epoch": 0.5240103164531051,
      "grad_norm": 0.014181618578732014,
      "learning_rate": 8.485494641153696e-06,
      "loss": 0.8279,
      "step": 3200
    },
    {
      "epoch": 0.5403856388422648,
      "grad_norm": 0.002023229608312249,
      "learning_rate": 8.429381067280175e-06,
      "loss": 0.8299,
      "step": 3300
    },
    {
      "epoch": 0.5567609612314243,
      "grad_norm": 0.0032021300867199898,
      "learning_rate": 8.373267493406656e-06,
      "loss": 0.8292,
      "step": 3400
    },
    {
      "epoch": 0.5731362836205838,
      "grad_norm": 0.014412829652428627,
      "learning_rate": 8.317153919533135e-06,
      "loss": 0.8299,
      "step": 3500
    },
    {
      "epoch": 0.5731362836205838,
      "eval_loss": 0.8221010565757751,
      "eval_runtime": 316.022,
      "eval_samples_per_second": 19.885,
      "eval_steps_per_second": 4.971,
      "step": 3500
    },
    {
      "epoch": 0.5895116060097433,
      "grad_norm": 0.00727146165445447,
      "learning_rate": 8.261040345659616e-06,
      "loss": 0.8299,
      "step": 3600
    },
    {
      "epoch": 0.6058869283989029,
      "grad_norm": 0.008680051192641258,
      "learning_rate": 8.204926771786096e-06,
      "loss": 0.8299,
      "step": 3700
    },
    {
      "epoch": 0.6222622507880624,
      "grad_norm": 0.0013599243247881532,
      "learning_rate": 8.148813197912576e-06,
      "loss": 0.8292,
      "step": 3800
    },
    {
      "epoch": 0.6386375731772219,
      "grad_norm": 0.0034652973990887403,
      "learning_rate": 8.092699624039056e-06,
      "loss": 0.8299,
      "step": 3900
    },
    {
      "epoch": 0.6550128955663814,
      "grad_norm": 0.001178682199679315,
      "learning_rate": 8.036586050165535e-06,
      "loss": 0.8299,
      "step": 4000
    },
    {
      "epoch": 0.6550128955663814,
      "eval_loss": 0.8219175934791565,
      "eval_runtime": 316.5573,
      "eval_samples_per_second": 19.851,
      "eval_steps_per_second": 4.963,
      "step": 4000
    },
    {
      "epoch": 0.671388217955541,
      "grad_norm": 0.0015170462429523468,
      "learning_rate": 7.980472476292016e-06,
      "loss": 0.83,
      "step": 4100
    },
    {
      "epoch": 0.6877635403447006,
      "grad_norm": 0.005117959342896938,
      "learning_rate": 7.924358902418495e-06,
      "loss": 0.8318,
      "step": 4200
    },
    {
      "epoch": 0.7041388627338601,
      "grad_norm": 0.0046030436642467976,
      "learning_rate": 7.868245328544976e-06,
      "loss": 0.8305,
      "step": 4300
    },
    {
      "epoch": 0.7205141851230196,
      "grad_norm": 0.004704657942056656,
      "learning_rate": 7.812131754671456e-06,
      "loss": 0.8285,
      "step": 4400
    },
    {
      "epoch": 0.7368895075121792,
      "grad_norm": 0.0026693621184676886,
      "learning_rate": 7.756018180797935e-06,
      "loss": 0.8292,
      "step": 4500
    },
    {
      "epoch": 0.7368895075121792,
      "eval_loss": 0.8218837976455688,
      "eval_runtime": 325.3294,
      "eval_samples_per_second": 19.316,
      "eval_steps_per_second": 4.829,
      "step": 4500
    },
    {
      "epoch": 0.7532648299013387,
      "grad_norm": 0.004493705462664366,
      "learning_rate": 7.699904606924416e-06,
      "loss": 0.8318,
      "step": 4600
    },
    {
      "epoch": 0.7696401522904982,
      "grad_norm": 0.0033772310707718134,
      "learning_rate": 7.643791033050895e-06,
      "loss": 0.8278,
      "step": 4700
    },
    {
      "epoch": 0.7860154746796577,
      "grad_norm": 0.0017833958845585585,
      "learning_rate": 7.587677459177376e-06,
      "loss": 0.8278,
      "step": 4800
    },
    {
      "epoch": 0.8023907970688173,
      "grad_norm": 0.0010591703467071056,
      "learning_rate": 7.5315638853038555e-06,
      "loss": 0.8311,
      "step": 4900
    },
    {
      "epoch": 0.8187661194579768,
      "grad_norm": 0.003258111886680126,
      "learning_rate": 7.475450311430336e-06,
      "loss": 0.8292,
      "step": 5000
    },
    {
      "epoch": 0.8187661194579768,
      "eval_loss": 0.8218579292297363,
      "eval_runtime": 319.6416,
      "eval_samples_per_second": 19.66,
      "eval_steps_per_second": 4.915,
      "step": 5000
    },
    {
      "epoch": 0.8351414418471363,
      "grad_norm": 0.0046092430129647255,
      "learning_rate": 7.419336737556816e-06,
      "loss": 0.8311,
      "step": 5100
    },
    {
      "epoch": 0.8515167642362959,
      "grad_norm": 0.01062753889709711,
      "learning_rate": 7.363223163683295e-06,
      "loss": 0.8298,
      "step": 5200
    },
    {
      "epoch": 0.8678920866254555,
      "grad_norm": 0.0011945065343752503,
      "learning_rate": 7.307109589809775e-06,
      "loss": 0.8298,
      "step": 5300
    },
    {
      "epoch": 0.884267409014615,
      "grad_norm": 0.001232060487382114,
      "learning_rate": 7.250996015936256e-06,
      "loss": 0.8292,
      "step": 5400
    },
    {
      "epoch": 0.9006427314037745,
      "grad_norm": 0.000989401713013649,
      "learning_rate": 7.194882442062736e-06,
      "loss": 0.8311,
      "step": 5500
    },
    {
      "epoch": 0.9006427314037745,
      "eval_loss": 0.8218740224838257,
      "eval_runtime": 322.3052,
      "eval_samples_per_second": 19.497,
      "eval_steps_per_second": 4.874,
      "step": 5500
    },
    {
      "epoch": 0.917018053792934,
      "grad_norm": 0.001544193597510457,
      "learning_rate": 7.138768868189216e-06,
      "loss": 0.8305,
      "step": 5600
    },
    {
      "epoch": 0.9333933761820936,
      "grad_norm": 0.0024662718642503023,
      "learning_rate": 7.082655294315696e-06,
      "loss": 0.8278,
      "step": 5700
    },
    {
      "epoch": 0.9497686985712531,
      "grad_norm": 0.0008593482198193669,
      "learning_rate": 7.026541720442176e-06,
      "loss": 0.8298,
      "step": 5800
    },
    {
      "epoch": 0.9661440209604126,
      "grad_norm": 0.002972190733999014,
      "learning_rate": 6.970428146568655e-06,
      "loss": 0.8311,
      "step": 5900
    },
    {
      "epoch": 0.9825193433495722,
      "grad_norm": 0.0007452499121427536,
      "learning_rate": 6.914314572695135e-06,
      "loss": 0.8291,
      "step": 6000
    },
    {
      "epoch": 0.9825193433495722,
      "eval_loss": 0.8218201398849487,
      "eval_runtime": 317.0459,
      "eval_samples_per_second": 19.82,
      "eval_steps_per_second": 4.955,
      "step": 6000
    },
    {
      "epoch": 0.9988946657387318,
      "grad_norm": 0.0008475783979520202,
      "learning_rate": 6.8582009988216155e-06,
      "loss": 0.8305,
      "step": 6100
    },
    {
      "epoch": 1.0152290498219183,
      "grad_norm": 0.0004145640123169869,
      "learning_rate": 6.802087424948095e-06,
      "loss": 0.8264,
      "step": 6200
    },
    {
      "epoch": 1.031604372211078,
      "grad_norm": 0.0013671296183019876,
      "learning_rate": 6.745973851074576e-06,
      "loss": 0.8278,
      "step": 6300
    },
    {
      "epoch": 1.0479796946002375,
      "grad_norm": 0.0011547701433300972,
      "learning_rate": 6.689860277201056e-06,
      "loss": 0.8305,
      "step": 6400
    },
    {
      "epoch": 1.064355016989397,
      "grad_norm": 0.002090979367494583,
      "learning_rate": 6.633746703327536e-06,
      "loss": 0.8285,
      "step": 6500
    },
    {
      "epoch": 1.064355016989397,
      "eval_loss": 0.8218199014663696,
      "eval_runtime": 316.4791,
      "eval_samples_per_second": 19.856,
      "eval_steps_per_second": 4.964,
      "step": 6500
    },
    {
      "epoch": 1.0807303393785566,
      "grad_norm": 0.0014565801247954369,
      "learning_rate": 6.577633129454015e-06,
      "loss": 0.8285,
      "step": 6600
    },
    {
      "epoch": 1.097105661767716,
      "grad_norm": 0.0055336663499474525,
      "learning_rate": 6.5215195555804954e-06,
      "loss": 0.8298,
      "step": 6700
    },
    {
      "epoch": 1.1134809841568756,
      "grad_norm": 0.00031413385295309126,
      "learning_rate": 6.465405981706976e-06,
      "loss": 0.8298,
      "step": 6800
    },
    {
      "epoch": 1.1298563065460352,
      "grad_norm": 0.0007711395155638456,
      "learning_rate": 6.409292407833455e-06,
      "loss": 0.8291,
      "step": 6900
    },
    {
      "epoch": 1.1462316289351946,
      "grad_norm": 0.00028513328288681805,
      "learning_rate": 6.353178833959935e-06,
      "loss": 0.8304,
      "step": 7000
    },
    {
      "epoch": 1.1462316289351946,
      "eval_loss": 0.8218072056770325,
      "eval_runtime": 318.1775,
      "eval_samples_per_second": 19.75,
      "eval_steps_per_second": 4.937,
      "step": 7000
    },
    {
      "epoch": 1.1626069513243542,
      "grad_norm": 0.00051884725689888,
      "learning_rate": 6.297065260086416e-06,
      "loss": 0.8298,
      "step": 7100
    },
    {
      "epoch": 1.1789822737135138,
      "grad_norm": 0.0002579925348982215,
      "learning_rate": 6.240951686212895e-06,
      "loss": 0.8311,
      "step": 7200
    },
    {
      "epoch": 1.1953575961026732,
      "grad_norm": 0.0002534630475565791,
      "learning_rate": 6.1848381123393754e-06,
      "loss": 0.8311,
      "step": 7300
    },
    {
      "epoch": 1.2117329184918328,
      "grad_norm": 0.0009162696660496294,
      "learning_rate": 6.1287245384658556e-06,
      "loss": 0.8318,
      "step": 7400
    },
    {
      "epoch": 1.2281082408809922,
      "grad_norm": 0.0006000589928589761,
      "learning_rate": 6.072610964592336e-06,
      "loss": 0.8278,
      "step": 7500
    },
    {
      "epoch": 1.2281082408809922,
      "eval_loss": 0.8218042850494385,
      "eval_runtime": 300.2547,
      "eval_samples_per_second": 20.929,
      "eval_steps_per_second": 5.232,
      "step": 7500
    },
    {
      "epoch": 1.2444835632701519,
      "grad_norm": 0.0002968305489048362,
      "learning_rate": 6.016497390718815e-06,
      "loss": 0.8278,
      "step": 7600
    },
    {
      "epoch": 1.2608588856593115,
      "grad_norm": 0.001746517838910222,
      "learning_rate": 5.960383816845295e-06,
      "loss": 0.8298,
      "step": 7700
    },
    {
      "epoch": 1.2772342080484709,
      "grad_norm": 0.00019910279661417007,
      "learning_rate": 5.904270242971776e-06,
      "loss": 0.8278,
      "step": 7800
    },
    {
      "epoch": 1.2936095304376305,
      "grad_norm": 0.0008095461525954306,
      "learning_rate": 5.8481566690982546e-06,
      "loss": 0.8298,
      "step": 7900
    },
    {
      "epoch": 1.3099848528267901,
      "grad_norm": 0.0005079837865196168,
      "learning_rate": 5.7920430952247356e-06,
      "loss": 0.8278,
      "step": 8000
    },
    {
      "epoch": 1.3099848528267901,
      "eval_loss": 0.8218517303466797,
      "eval_runtime": 307.2706,
      "eval_samples_per_second": 20.451,
      "eval_steps_per_second": 5.113,
      "step": 8000
    },
    {
      "epoch": 1.3263601752159495,
      "grad_norm": 0.0037674049381166697,
      "learning_rate": 5.735929521351216e-06,
      "loss": 0.8265,
      "step": 8100
    },
    {
      "epoch": 1.3427354976051091,
      "grad_norm": 0.0001519332581665367,
      "learning_rate": 5.679815947477695e-06,
      "loss": 0.8298,
      "step": 8200
    },
    {
      "epoch": 1.3591108199942687,
      "grad_norm": 0.024659298360347748,
      "learning_rate": 5.623702373604175e-06,
      "loss": 0.8318,
      "step": 8300
    },
    {
      "epoch": 1.3754861423834281,
      "grad_norm": 0.00016496548778377473,
      "learning_rate": 5.567588799730655e-06,
      "loss": 0.8298,
      "step": 8400
    },
    {
      "epoch": 1.3918614647725878,
      "grad_norm": 0.0006325372960418463,
      "learning_rate": 5.511475225857135e-06,
      "loss": 0.8278,
      "step": 8500
    },
    {
      "epoch": 1.3918614647725878,
      "eval_loss": 0.8218000531196594,
      "eval_runtime": 302.4472,
      "eval_samples_per_second": 20.777,
      "eval_steps_per_second": 5.194,
      "step": 8500
    },
    {
      "epoch": 1.4082367871617474,
      "grad_norm": 0.00033877824898809195,
      "learning_rate": 5.455361651983615e-06,
      "loss": 0.8285,
      "step": 8600
    },
    {
      "epoch": 1.4246121095509068,
      "grad_norm": 0.0001895879249786958,
      "learning_rate": 5.399248078110096e-06,
      "loss": 0.8304,
      "step": 8700
    },
    {
      "epoch": 1.4409874319400664,
      "grad_norm": 0.00022361565788742155,
      "learning_rate": 5.343134504236576e-06,
      "loss": 0.8318,
      "step": 8800
    },
    {
      "epoch": 1.4573627543292258,
      "grad_norm": 9.477894491283223e-05,
      "learning_rate": 5.287020930363055e-06,
      "loss": 0.8291,
      "step": 8900
    },
    {
      "epoch": 1.4737380767183854,
      "grad_norm": 0.0002235100109828636,
      "learning_rate": 5.230907356489535e-06,
      "loss": 0.8311,
      "step": 9000
    },
    {
      "epoch": 1.4737380767183854,
      "eval_loss": 0.8217957019805908,
      "eval_runtime": 297.8106,
      "eval_samples_per_second": 21.101,
      "eval_steps_per_second": 5.275,
      "step": 9000
    },
    {
      "epoch": 1.4901133991075448,
      "grad_norm": 0.00017001002561300993,
      "learning_rate": 5.174793782616015e-06,
      "loss": 0.8311,
      "step": 9100
    },
    {
      "epoch": 1.5064887214967044,
      "grad_norm": 0.00020385452080518007,
      "learning_rate": 5.118680208742495e-06,
      "loss": 0.8278,
      "step": 9200
    },
    {
      "epoch": 1.522864043885864,
      "grad_norm": 0.00019935690215788782,
      "learning_rate": 5.062566634868975e-06,
      "loss": 0.8278,
      "step": 9300
    },
    {
      "epoch": 1.5392393662750234,
      "grad_norm": 0.00018737305072136223,
      "learning_rate": 5.006453060995455e-06,
      "loss": 0.8304,
      "step": 9400
    },
    {
      "epoch": 1.555614688664183,
      "grad_norm": 0.0002984873717650771,
      "learning_rate": 4.950339487121935e-06,
      "loss": 0.8285,
      "step": 9500
    },
    {
      "epoch": 1.555614688664183,
      "eval_loss": 0.8217952251434326,
      "eval_runtime": 300.9403,
      "eval_samples_per_second": 20.881,
      "eval_steps_per_second": 5.22,
      "step": 9500
    },
    {
      "epoch": 1.5719900110533427,
      "grad_norm": 0.00024070791550911963,
      "learning_rate": 4.894225913248415e-06,
      "loss": 0.8298,
      "step": 9600
    },
    {
      "epoch": 1.588365333442502,
      "grad_norm": 0.00010199127427767962,
      "learning_rate": 4.838112339374895e-06,
      "loss": 0.8304,
      "step": 9700
    },
    {
      "epoch": 1.6047406558316617,
      "grad_norm": 0.00022348998754750937,
      "learning_rate": 4.781998765501375e-06,
      "loss": 0.8298,
      "step": 9800
    },
    {
      "epoch": 1.6211159782208213,
      "grad_norm": 0.00020255437993910164,
      "learning_rate": 4.725885191627856e-06,
      "loss": 0.8285,
      "step": 9900
    },
    {
      "epoch": 1.6374913006099807,
      "grad_norm": 0.00035430557909421623,
      "learning_rate": 4.669771617754335e-06,
      "loss": 0.8298,
      "step": 10000
    },
    {
      "epoch": 1.6374913006099807,
      "eval_loss": 0.8217944502830505,
      "eval_runtime": 297.2907,
      "eval_samples_per_second": 21.138,
      "eval_steps_per_second": 5.284,
      "step": 10000
    },
    {
      "epoch": 1.6538666229991403,
      "grad_norm": 0.00010459680197527632,
      "learning_rate": 4.613658043880815e-06,
      "loss": 0.8298,
      "step": 10100
    },
    {
      "epoch": 1.6702419453883,
      "grad_norm": 0.00013105850666761398,
      "learning_rate": 4.557544470007295e-06,
      "loss": 0.8298,
      "step": 10200
    },
    {
      "epoch": 1.6866172677774594,
      "grad_norm": 0.0002607002679724246,
      "learning_rate": 4.5014308961337745e-06,
      "loss": 0.8311,
      "step": 10300
    },
    {
      "epoch": 1.7029925901666187,
      "grad_norm": 0.0003258515789639205,
      "learning_rate": 4.4453173222602555e-06,
      "loss": 0.8304,
      "step": 10400
    },
    {
      "epoch": 1.7193679125557786,
      "grad_norm": 0.00021283880050759763,
      "learning_rate": 4.389203748386735e-06,
      "loss": 0.8291,
      "step": 10500
    },
    {
      "epoch": 1.7193679125557786,
      "eval_loss": 0.8217933773994446,
      "eval_runtime": 299.4394,
      "eval_samples_per_second": 20.986,
      "eval_steps_per_second": 5.246,
      "step": 10500
    },
    {
      "epoch": 1.735743234944938,
      "grad_norm": 0.00021780711540486664,
      "learning_rate": 4.333090174513215e-06,
      "loss": 0.8291,
      "step": 10600
    },
    {
      "epoch": 1.7521185573340974,
      "grad_norm": 5.7399782235734165e-05,
      "learning_rate": 4.276976600639695e-06,
      "loss": 0.8311,
      "step": 10700
    },
    {
      "epoch": 1.768493879723257,
      "grad_norm": 0.0001786022912710905,
      "learning_rate": 4.220863026766175e-06,
      "loss": 0.8285,
      "step": 10800
    },
    {
      "epoch": 1.7848692021124166,
      "grad_norm": 0.00012947505456395447,
      "learning_rate": 4.164749452892655e-06,
      "loss": 0.8271,
      "step": 10900
    },
    {
      "epoch": 1.801244524501576,
      "grad_norm": 0.00021354241471271962,
      "learning_rate": 4.108635879019135e-06,
      "loss": 0.8311,
      "step": 11000
    },
    {
      "epoch": 1.801244524501576,
      "eval_loss": 0.8217933773994446,
      "eval_runtime": 298.4623,
      "eval_samples_per_second": 21.055,
      "eval_steps_per_second": 5.264,
      "step": 11000
    },
    {
      "epoch": 1.8176198468907356,
      "grad_norm": 0.00022429587261285633,
      "learning_rate": 4.052522305145616e-06,
      "loss": 0.8291,
      "step": 11100
    },
    {
      "epoch": 1.8339951692798953,
      "grad_norm": 0.0003482870233710855,
      "learning_rate": 3.996408731272095e-06,
      "loss": 0.8311,
      "step": 11200
    },
    {
      "epoch": 1.8503704916690547,
      "grad_norm": 7.105170516297221e-05,
      "learning_rate": 3.940295157398575e-06,
      "loss": 0.8298,
      "step": 11300
    },
    {
      "epoch": 1.8667458140582143,
      "grad_norm": 0.00021123094484210014,
      "learning_rate": 3.884181583525055e-06,
      "loss": 0.8298,
      "step": 11400
    },
    {
      "epoch": 1.8831211364473739,
      "grad_norm": 0.0001702254667179659,
      "learning_rate": 3.8280680096515345e-06,
      "loss": 0.8298,
      "step": 11500
    },
    {
      "epoch": 1.8831211364473739,
      "eval_loss": 0.8217926025390625,
      "eval_runtime": 299.7201,
      "eval_samples_per_second": 20.966,
      "eval_steps_per_second": 5.242,
      "step": 11500
    },
    {
      "epoch": 1.8994964588365333,
      "grad_norm": 0.00011197683488717303,
      "learning_rate": 3.771954435778015e-06,
      "loss": 0.8311,
      "step": 11600
    },
    {
      "epoch": 1.915871781225693,
      "grad_norm": 7.091157021932304e-05,
      "learning_rate": 3.715840861904495e-06,
      "loss": 0.8304,
      "step": 11700
    },
    {
      "epoch": 1.9322471036148525,
      "grad_norm": 5.477948434418067e-05,
      "learning_rate": 3.659727288030975e-06,
      "loss": 0.8271,
      "step": 11800
    },
    {
      "epoch": 1.948622426004012,
      "grad_norm": 6.311854667728767e-05,
      "learning_rate": 3.603613714157455e-06,
      "loss": 0.8304,
      "step": 11900
    },
    {
      "epoch": 1.9649977483931715,
      "grad_norm": 7.76556771597825e-05,
      "learning_rate": 3.5475001402839348e-06,
      "loss": 0.8304,
      "step": 12000
    },
    {
      "epoch": 1.9649977483931715,
      "eval_loss": 0.8217965960502625,
      "eval_runtime": 299.8856,
      "eval_samples_per_second": 20.955,
      "eval_steps_per_second": 5.239,
      "step": 12000
    },
    {
      "epoch": 1.9813730707823312,
      "grad_norm": 7.102093513822183e-05,
      "learning_rate": 3.4913865664104153e-06,
      "loss": 0.8291,
      "step": 12100
    },
    {
      "epoch": 1.9977483931714906,
      "grad_norm": 0.0001388480159221217,
      "learning_rate": 3.435272992536895e-06,
      "loss": 0.8304,
      "step": 12200
    },
    {
      "epoch": 2.014082777254677,
      "grad_norm": 4.336753409006633e-05,
      "learning_rate": 3.3791594186633748e-06,
      "loss": 0.8264,
      "step": 12300
    },
    {
      "epoch": 2.0304580996438366,
      "grad_norm": 9.701675298856571e-05,
      "learning_rate": 3.323045844789855e-06,
      "loss": 0.8278,
      "step": 12400
    },
    {
      "epoch": 2.0468334220329965,
      "grad_norm": 9.370150655740872e-05,
      "learning_rate": 3.2669322709163346e-06,
      "loss": 0.8304,
      "step": 12500
    },
    {
      "epoch": 2.0468334220329965,
      "eval_loss": 0.821790874004364,
      "eval_runtime": 301.961,
      "eval_samples_per_second": 20.811,
      "eval_steps_per_second": 5.203,
      "step": 12500
    },
    {
      "epoch": 2.063208744422156,
      "grad_norm": 5.034494461142458e-05,
      "learning_rate": 3.210818697042815e-06,
      "loss": 0.8298,
      "step": 12600
    },
    {
      "epoch": 2.0795840668113152,
      "grad_norm": 4.749705476569943e-05,
      "learning_rate": 3.154705123169295e-06,
      "loss": 0.8271,
      "step": 12700
    },
    {
      "epoch": 2.095959389200475,
      "grad_norm": 7.189447205746546e-05,
      "learning_rate": 3.0985915492957746e-06,
      "loss": 0.8298,
      "step": 12800
    },
    {
      "epoch": 2.1123347115896345,
      "grad_norm": 2.8672247935901396e-05,
      "learning_rate": 3.042477975422255e-06,
      "loss": 0.8304,
      "step": 12900
    },
    {
      "epoch": 2.128710033978794,
      "grad_norm": 5.833296017954126e-05,
      "learning_rate": 2.986364401548735e-06,
      "loss": 0.8291,
      "step": 13000
    },
    {
      "epoch": 2.128710033978794,
      "eval_loss": 0.8217904567718506,
      "eval_runtime": 300.4957,
      "eval_samples_per_second": 20.912,
      "eval_steps_per_second": 5.228,
      "step": 13000
    },
    {
      "epoch": 2.1450853563679537,
      "grad_norm": 2.922881867561955e-05,
      "learning_rate": 2.930250827675215e-06,
      "loss": 0.8298,
      "step": 13100
    },
    {
      "epoch": 2.161460678757113,
      "grad_norm": 0.0001947234704857692,
      "learning_rate": 2.8741372538016947e-06,
      "loss": 0.8298,
      "step": 13200
    },
    {
      "epoch": 2.1778360011462725,
      "grad_norm": 0.0024234794545918703,
      "learning_rate": 2.8180236799281745e-06,
      "loss": 0.8311,
      "step": 13300
    },
    {
      "epoch": 2.194211323535432,
      "grad_norm": 0.00010103421664098278,
      "learning_rate": 2.761910106054655e-06,
      "loss": 0.8311,
      "step": 13400
    },
    {
      "epoch": 2.2105866459245918,
      "grad_norm": 2.691950612643268e-05,
      "learning_rate": 2.7057965321811347e-06,
      "loss": 0.8317,
      "step": 13500
    },
    {
      "epoch": 2.2105866459245918,
      "eval_loss": 0.8217902183532715,
      "eval_runtime": 299.7815,
      "eval_samples_per_second": 20.962,
      "eval_steps_per_second": 5.24,
      "step": 13500
    },
    {
      "epoch": 2.226961968313751,
      "grad_norm": 8.944373985286802e-05,
      "learning_rate": 2.649682958307615e-06,
      "loss": 0.8284,
      "step": 13600
    },
    {
      "epoch": 2.2433372907029105,
      "grad_norm": 0.000602410698775202,
      "learning_rate": 2.5935693844340946e-06,
      "loss": 0.8271,
      "step": 13700
    },
    {
      "epoch": 2.2597126130920704,
      "grad_norm": 7.892262510722503e-05,
      "learning_rate": 2.5374558105605747e-06,
      "loss": 0.8298,
      "step": 13800
    },
    {
      "epoch": 2.27608793548123,
      "grad_norm": 0.00012469316425267607,
      "learning_rate": 2.481342236687055e-06,
      "loss": 0.8291,
      "step": 13900
    },
    {
      "epoch": 2.292463257870389,
      "grad_norm": 0.00010102442320203409,
      "learning_rate": 2.425228662813535e-06,
      "loss": 0.8284,
      "step": 14000
    },
    {
      "epoch": 2.292463257870389,
      "eval_loss": 0.8217899203300476,
      "eval_runtime": 291.7948,
      "eval_samples_per_second": 21.536,
      "eval_steps_per_second": 5.384,
      "step": 14000
    },
    {
      "epoch": 2.308838580259549,
      "grad_norm": 4.816008367924951e-05,
      "learning_rate": 2.3691150889400147e-06,
      "loss": 0.8284,
      "step": 14100
    },
    {
      "epoch": 2.3252139026487084,
      "grad_norm": 4.601872933562845e-05,
      "learning_rate": 2.313001515066495e-06,
      "loss": 0.8265,
      "step": 14200
    },
    {
      "epoch": 2.341589225037868,
      "grad_norm": 6.285431300057098e-05,
      "learning_rate": 2.2568879411929746e-06,
      "loss": 0.8298,
      "step": 14300
    },
    {
      "epoch": 2.3579645474270277,
      "grad_norm": 3.751591793843545e-05,
      "learning_rate": 2.2007743673194547e-06,
      "loss": 0.8317,
      "step": 14400
    },
    {
      "epoch": 2.374339869816187,
      "grad_norm": 3.892002860084176e-05,
      "learning_rate": 2.144660793445935e-06,
      "loss": 0.8291,
      "step": 14500
    },
    {
      "epoch": 2.374339869816187,
      "eval_loss": 0.8217898607254028,
      "eval_runtime": 290.0499,
      "eval_samples_per_second": 21.665,
      "eval_steps_per_second": 5.416,
      "step": 14500
    },
    {
      "epoch": 2.3907151922053465,
      "grad_norm": 5.872089968761429e-05,
      "learning_rate": 2.0885472195724146e-06,
      "loss": 0.8284,
      "step": 14600
    },
    {
      "epoch": 2.407090514594506,
      "grad_norm": 2.1740685042459518e-05,
      "learning_rate": 2.0324336456988947e-06,
      "loss": 0.8291,
      "step": 14700
    },
    {
      "epoch": 2.4234658369836657,
      "grad_norm": 1.6683339708833955e-05,
      "learning_rate": 1.976320071825375e-06,
      "loss": 0.8298,
      "step": 14800
    },
    {
      "epoch": 2.439841159372825,
      "grad_norm": 6.494174886029214e-05,
      "learning_rate": 1.9202064979518546e-06,
      "loss": 0.8311,
      "step": 14900
    },
    {
      "epoch": 2.4562164817619845,
      "grad_norm": 2.385848893027287e-05,
      "learning_rate": 1.864092924078335e-06,
      "loss": 0.8291,
      "step": 15000
    },
    {
      "epoch": 2.4562164817619845,
      "eval_loss": 0.8217896223068237,
      "eval_runtime": 288.955,
      "eval_samples_per_second": 21.747,
      "eval_steps_per_second": 5.437,
      "step": 15000
    },
    {
      "epoch": 2.4725918041511443,
      "grad_norm": 1.9237770175095648e-05,
      "learning_rate": 1.8079793502048146e-06,
      "loss": 0.8311,
      "step": 15100
    },
    {
      "epoch": 2.4889671265403037,
      "grad_norm": 1.8489055946702138e-05,
      "learning_rate": 1.7518657763312946e-06,
      "loss": 0.8311,
      "step": 15200
    },
    {
      "epoch": 2.505342448929463,
      "grad_norm": 1.5796773368492723e-05,
      "learning_rate": 1.6957522024577747e-06,
      "loss": 0.8278,
      "step": 15300
    },
    {
      "epoch": 2.521717771318623,
      "grad_norm": 1.3803705769532826e-05,
      "learning_rate": 1.6396386285842546e-06,
      "loss": 0.8278,
      "step": 15400
    },
    {
      "epoch": 2.5380930937077824,
      "grad_norm": 4.085306863998994e-05,
      "learning_rate": 1.5835250547107348e-06,
      "loss": 0.8304,
      "step": 15500
    },
    {
      "epoch": 2.5380930937077824,
      "eval_loss": 0.8217896819114685,
      "eval_runtime": 300.7879,
      "eval_samples_per_second": 20.892,
      "eval_steps_per_second": 5.223,
      "step": 15500
    },
    {
      "epoch": 2.5544684160969418,
      "grad_norm": 2.6989235266228206e-05,
      "learning_rate": 1.5274114808372145e-06,
      "loss": 0.8284,
      "step": 15600
    },
    {
      "epoch": 2.5708437384861016,
      "grad_norm": 2.9494769478333183e-05,
      "learning_rate": 1.4712979069636946e-06,
      "loss": 0.8304,
      "step": 15700
    },
    {
      "epoch": 2.587219060875261,
      "grad_norm": 2.9886146876378916e-05,
      "learning_rate": 1.4151843330901745e-06,
      "loss": 0.8298,
      "step": 15800
    },
    {
      "epoch": 2.6035943832644204,
      "grad_norm": 4.256200554664247e-05,
      "learning_rate": 1.3590707592166547e-06,
      "loss": 0.8298,
      "step": 15900
    },
    {
      "epoch": 2.6199697056535802,
      "grad_norm": 1.7169191778521053e-05,
      "learning_rate": 1.3029571853431346e-06,
      "loss": 0.8284,
      "step": 16000
    },
    {
      "epoch": 2.6199697056535802,
      "eval_loss": 0.8217893242835999,
      "eval_runtime": 290.1767,
      "eval_samples_per_second": 21.656,
      "eval_steps_per_second": 5.414,
      "step": 16000
    },
    {
      "epoch": 2.6363450280427396,
      "grad_norm": 7.001629273872823e-05,
      "learning_rate": 1.2468436114696145e-06,
      "loss": 0.8304,
      "step": 16100
    },
    {
      "epoch": 2.652720350431899,
      "grad_norm": 3.680654845084064e-05,
      "learning_rate": 1.1907300375960947e-06,
      "loss": 0.8291,
      "step": 16200
    },
    {
      "epoch": 2.669095672821059,
      "grad_norm": 1.8394926883047447e-05,
      "learning_rate": 1.1346164637225746e-06,
      "loss": 0.8304,
      "step": 16300
    },
    {
      "epoch": 2.6854709952102183,
      "grad_norm": 2.048616443062201e-05,
      "learning_rate": 1.0785028898490545e-06,
      "loss": 0.8304,
      "step": 16400
    },
    {
      "epoch": 2.7018463175993777,
      "grad_norm": 4.5219523599371314e-05,
      "learning_rate": 1.0223893159755345e-06,
      "loss": 0.8304,
      "step": 16500
    },
    {
      "epoch": 2.7018463175993777,
      "eval_loss": 0.8217893242835999,
      "eval_runtime": 291.2411,
      "eval_samples_per_second": 21.577,
      "eval_steps_per_second": 5.394,
      "step": 16500
    },
    {
      "epoch": 2.7182216399885375,
      "grad_norm": 4.342350075603463e-05,
      "learning_rate": 9.662757421020146e-07,
      "loss": 0.8291,
      "step": 16600
    },
    {
      "epoch": 2.734596962377697,
      "grad_norm": 9.680826224212069e-06,
      "learning_rate": 9.101621682284946e-07,
      "loss": 0.8291,
      "step": 16700
    },
    {
      "epoch": 2.7509722847668563,
      "grad_norm": 5.320965647115372e-05,
      "learning_rate": 8.540485943549746e-07,
      "loss": 0.8311,
      "step": 16800
    },
    {
      "epoch": 2.767347607156016,
      "grad_norm": 9.871078873402439e-06,
      "learning_rate": 7.979350204814546e-07,
      "loss": 0.8284,
      "step": 16900
    },
    {
      "epoch": 2.7837229295451755,
      "grad_norm": 4.4034870370524004e-05,
      "learning_rate": 7.418214466079344e-07,
      "loss": 0.8271,
      "step": 17000
    },
    {
      "epoch": 2.7837229295451755,
      "eval_loss": 0.8217891454696655,
      "eval_runtime": 289.6078,
      "eval_samples_per_second": 21.698,
      "eval_steps_per_second": 5.425,
      "step": 17000
    },
    {
      "epoch": 2.800098251934335,
      "grad_norm": 0.00011076083319494501,
      "learning_rate": 6.857078727344145e-07,
      "loss": 0.8311,
      "step": 17100
    },
    {
      "epoch": 2.8164735743234948,
      "grad_norm": 7.359300980169792e-06,
      "learning_rate": 6.295942988608946e-07,
      "loss": 0.8291,
      "step": 17200
    },
    {
      "epoch": 2.832848896712654,
      "grad_norm": 0.00012428828631527722,
      "learning_rate": 5.734807249873745e-07,
      "loss": 0.8317,
      "step": 17300
    },
    {
      "epoch": 2.8492242191018136,
      "grad_norm": 1.9342889572726563e-05,
      "learning_rate": 5.173671511138545e-07,
      "loss": 0.8298,
      "step": 17400
    },
    {
      "epoch": 2.865599541490973,
      "grad_norm": 2.4349566956516355e-05,
      "learning_rate": 4.6125357724033446e-07,
      "loss": 0.8291,
      "step": 17500
    },
    {
      "epoch": 2.865599541490973,
      "eval_loss": 0.8217900991439819,
      "eval_runtime": 293.9572,
      "eval_samples_per_second": 21.377,
      "eval_steps_per_second": 5.344,
      "step": 17500
    }
  ],
  "logging_steps": 100,
  "max_steps": 18321,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
