{
  "best_global_step": 18000,
  "best_metric": 0.6928142309188843,
  "best_model_checkpoint": "/data3/gkook/temp/agi/canary-qwen-2.5b_ft_result_v2/checkpoint-18000",
  "epoch": 2.947476153436771,
  "eval_steps": 500,
  "global_step": 18000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016375322389159536,
      "grad_norm": 1.799020528793335,
      "learning_rate": 1.98e-06,
      "loss": 7.9735,
      "step": 100
    },
    {
      "epoch": 0.03275064477831907,
      "grad_norm": 2.329383134841919,
      "learning_rate": 3.980000000000001e-06,
      "loss": 7.9211,
      "step": 200
    },
    {
      "epoch": 0.04912596716747861,
      "grad_norm": 3.0208022594451904,
      "learning_rate": 5.98e-06,
      "loss": 7.6412,
      "step": 300
    },
    {
      "epoch": 0.06550128955663814,
      "grad_norm": 4.478973865509033,
      "learning_rate": 7.980000000000002e-06,
      "loss": 6.9391,
      "step": 400
    },
    {
      "epoch": 0.08187661194579768,
      "grad_norm": 4.988444805145264,
      "learning_rate": 9.980000000000001e-06,
      "loss": 5.6225,
      "step": 500
    },
    {
      "epoch": 0.08187661194579768,
      "eval_loss": 4.8565287590026855,
      "eval_runtime": 299.7814,
      "eval_samples_per_second": 20.962,
      "eval_steps_per_second": 5.24,
      "step": 500
    },
    {
      "epoch": 0.09825193433495721,
      "grad_norm": 4.081057548522949,
      "learning_rate": 9.944447561865215e-06,
      "loss": 4.0826,
      "step": 600
    },
    {
      "epoch": 0.11462725672411675,
      "grad_norm": 1.5589879751205444,
      "learning_rate": 9.888333987991696e-06,
      "loss": 3.0323,
      "step": 700
    },
    {
      "epoch": 0.13100257911327629,
      "grad_norm": 2.204875946044922,
      "learning_rate": 9.832220414118176e-06,
      "loss": 2.6849,
      "step": 800
    },
    {
      "epoch": 0.14737790150243582,
      "grad_norm": 2.985858678817749,
      "learning_rate": 9.776106840244655e-06,
      "loss": 2.2738,
      "step": 900
    },
    {
      "epoch": 0.16375322389159536,
      "grad_norm": 0.4760505259037018,
      "learning_rate": 9.719993266371136e-06,
      "loss": 1.6633,
      "step": 1000
    },
    {
      "epoch": 0.16375322389159536,
      "eval_loss": 1.4972959756851196,
      "eval_runtime": 299.0755,
      "eval_samples_per_second": 21.011,
      "eval_steps_per_second": 5.253,
      "step": 1000
    },
    {
      "epoch": 0.1801285462807549,
      "grad_norm": 0.5527172088623047,
      "learning_rate": 9.663879692497617e-06,
      "loss": 1.4829,
      "step": 1100
    },
    {
      "epoch": 0.19650386866991443,
      "grad_norm": 0.6876918077468872,
      "learning_rate": 9.607766118624096e-06,
      "loss": 1.4327,
      "step": 1200
    },
    {
      "epoch": 0.21287919105907396,
      "grad_norm": 0.8626183867454529,
      "learning_rate": 9.551652544750576e-06,
      "loss": 1.3766,
      "step": 1300
    },
    {
      "epoch": 0.2292545134482335,
      "grad_norm": 1.4412964582443237,
      "learning_rate": 9.495538970877057e-06,
      "loss": 1.2874,
      "step": 1400
    },
    {
      "epoch": 0.24562983583739306,
      "grad_norm": 1.5702941417694092,
      "learning_rate": 9.439425397003536e-06,
      "loss": 1.0118,
      "step": 1500
    },
    {
      "epoch": 0.24562983583739306,
      "eval_loss": 0.7636330127716064,
      "eval_runtime": 298.7044,
      "eval_samples_per_second": 21.038,
      "eval_steps_per_second": 5.259,
      "step": 1500
    },
    {
      "epoch": 0.26200515822655257,
      "grad_norm": 0.11046264320611954,
      "learning_rate": 9.383311823130015e-06,
      "loss": 0.72,
      "step": 1600
    },
    {
      "epoch": 0.27838048061571213,
      "grad_norm": 0.07899307459592819,
      "learning_rate": 9.327198249256496e-06,
      "loss": 0.7027,
      "step": 1700
    },
    {
      "epoch": 0.29475580300487164,
      "grad_norm": 0.295187383890152,
      "learning_rate": 9.271084675382977e-06,
      "loss": 0.7012,
      "step": 1800
    },
    {
      "epoch": 0.3111311253940312,
      "grad_norm": 0.04646556079387665,
      "learning_rate": 9.214971101509456e-06,
      "loss": 0.701,
      "step": 1900
    },
    {
      "epoch": 0.3275064477831907,
      "grad_norm": 0.07924230396747589,
      "learning_rate": 9.158857527635936e-06,
      "loss": 0.6983,
      "step": 2000
    },
    {
      "epoch": 0.3275064477831907,
      "eval_loss": 0.6942229866981506,
      "eval_runtime": 299.1171,
      "eval_samples_per_second": 21.008,
      "eval_steps_per_second": 5.252,
      "step": 2000
    },
    {
      "epoch": 0.3438817701723503,
      "grad_norm": 0.02753562666475773,
      "learning_rate": 9.102743953762417e-06,
      "loss": 0.7011,
      "step": 2100
    },
    {
      "epoch": 0.3602570925615098,
      "grad_norm": 0.027817225083708763,
      "learning_rate": 9.046630379888896e-06,
      "loss": 0.702,
      "step": 2200
    },
    {
      "epoch": 0.37663241495066935,
      "grad_norm": 0.05933334678411484,
      "learning_rate": 8.990516806015375e-06,
      "loss": 0.701,
      "step": 2300
    },
    {
      "epoch": 0.39300773733982886,
      "grad_norm": 0.022206520661711693,
      "learning_rate": 8.934403232141856e-06,
      "loss": 0.6986,
      "step": 2400
    },
    {
      "epoch": 0.4093830597289884,
      "grad_norm": 0.0247745793312788,
      "learning_rate": 8.878289658268336e-06,
      "loss": 0.6996,
      "step": 2500
    },
    {
      "epoch": 0.4093830597289884,
      "eval_loss": 0.6935130953788757,
      "eval_runtime": 299.6065,
      "eval_samples_per_second": 20.974,
      "eval_steps_per_second": 5.244,
      "step": 2500
    },
    {
      "epoch": 0.4257583821181479,
      "grad_norm": 0.012677901424467564,
      "learning_rate": 8.822176084394815e-06,
      "loss": 0.701,
      "step": 2600
    },
    {
      "epoch": 0.4421337045073075,
      "grad_norm": 0.008454757742583752,
      "learning_rate": 8.766062510521296e-06,
      "loss": 0.7007,
      "step": 2700
    },
    {
      "epoch": 0.458509026896467,
      "grad_norm": 0.005971611477434635,
      "learning_rate": 8.709948936647777e-06,
      "loss": 0.7006,
      "step": 2800
    },
    {
      "epoch": 0.47488434928562656,
      "grad_norm": 0.008601085282862186,
      "learning_rate": 8.653835362774256e-06,
      "loss": 0.7012,
      "step": 2900
    },
    {
      "epoch": 0.4912596716747861,
      "grad_norm": 0.0071344925090670586,
      "learning_rate": 8.597721788900735e-06,
      "loss": 0.7011,
      "step": 3000
    },
    {
      "epoch": 0.4912596716747861,
      "eval_loss": 0.693185031414032,
      "eval_runtime": 301.5183,
      "eval_samples_per_second": 20.841,
      "eval_steps_per_second": 5.21,
      "step": 3000
    },
    {
      "epoch": 0.5076349940639456,
      "grad_norm": 0.022621048614382744,
      "learning_rate": 8.541608215027216e-06,
      "loss": 0.6984,
      "step": 3100
    },
    {
      "epoch": 0.5240103164531051,
      "grad_norm": 0.00396011071279645,
      "learning_rate": 8.485494641153696e-06,
      "loss": 0.6982,
      "step": 3200
    },
    {
      "epoch": 0.5403856388422648,
      "grad_norm": 0.01440348755568266,
      "learning_rate": 8.429381067280175e-06,
      "loss": 0.6999,
      "step": 3300
    },
    {
      "epoch": 0.5567609612314243,
      "grad_norm": 0.004980154801160097,
      "learning_rate": 8.373267493406656e-06,
      "loss": 0.6993,
      "step": 3400
    },
    {
      "epoch": 0.5731362836205838,
      "grad_norm": 0.009409284219145775,
      "learning_rate": 8.317153919533135e-06,
      "loss": 0.6998,
      "step": 3500
    },
    {
      "epoch": 0.5731362836205838,
      "eval_loss": 0.6931305527687073,
      "eval_runtime": 297.4084,
      "eval_samples_per_second": 21.129,
      "eval_steps_per_second": 5.282,
      "step": 3500
    },
    {
      "epoch": 0.5895116060097433,
      "grad_norm": 0.0036785805132240057,
      "learning_rate": 8.261040345659616e-06,
      "loss": 0.6998,
      "step": 3600
    },
    {
      "epoch": 0.6058869283989029,
      "grad_norm": 0.00637439452111721,
      "learning_rate": 8.204926771786096e-06,
      "loss": 0.6998,
      "step": 3700
    },
    {
      "epoch": 0.6222622507880624,
      "grad_norm": 0.005026406142860651,
      "learning_rate": 8.148813197912576e-06,
      "loss": 0.6994,
      "step": 3800
    },
    {
      "epoch": 0.6386375731772219,
      "grad_norm": 0.0026996692176908255,
      "learning_rate": 8.092699624039056e-06,
      "loss": 0.6998,
      "step": 3900
    },
    {
      "epoch": 0.6550128955663814,
      "grad_norm": 0.003314326284453273,
      "learning_rate": 8.036586050165535e-06,
      "loss": 0.6998,
      "step": 4000
    },
    {
      "epoch": 0.6550128955663814,
      "eval_loss": 0.6930050253868103,
      "eval_runtime": 301.0624,
      "eval_samples_per_second": 20.873,
      "eval_steps_per_second": 5.218,
      "step": 4000
    },
    {
      "epoch": 0.671388217955541,
      "grad_norm": 0.007002819329500198,
      "learning_rate": 7.980472476292016e-06,
      "loss": 0.6997,
      "step": 4100
    },
    {
      "epoch": 0.6877635403447006,
      "grad_norm": 0.016857964918017387,
      "learning_rate": 7.924358902418495e-06,
      "loss": 0.7009,
      "step": 4200
    },
    {
      "epoch": 0.7041388627338601,
      "grad_norm": 0.0039709340780973434,
      "learning_rate": 7.868245328544976e-06,
      "loss": 0.7004,
      "step": 4300
    },
    {
      "epoch": 0.7205141851230196,
      "grad_norm": 0.007956278510391712,
      "learning_rate": 7.812131754671456e-06,
      "loss": 0.6986,
      "step": 4400
    },
    {
      "epoch": 0.7368895075121792,
      "grad_norm": 0.004918637685477734,
      "learning_rate": 7.756018180797935e-06,
      "loss": 0.6992,
      "step": 4500
    },
    {
      "epoch": 0.7368895075121792,
      "eval_loss": 0.6929629445075989,
      "eval_runtime": 299.6971,
      "eval_samples_per_second": 20.968,
      "eval_steps_per_second": 5.242,
      "step": 4500
    },
    {
      "epoch": 0.7532648299013387,
      "grad_norm": 0.005032989662140608,
      "learning_rate": 7.699904606924416e-06,
      "loss": 0.7014,
      "step": 4600
    },
    {
      "epoch": 0.7696401522904982,
      "grad_norm": 0.004579918924719095,
      "learning_rate": 7.643791033050895e-06,
      "loss": 0.698,
      "step": 4700
    },
    {
      "epoch": 0.7860154746796577,
      "grad_norm": 0.005765884183347225,
      "learning_rate": 7.587677459177376e-06,
      "loss": 0.698,
      "step": 4800
    },
    {
      "epoch": 0.8023907970688173,
      "grad_norm": 0.006607670336961746,
      "learning_rate": 7.5315638853038555e-06,
      "loss": 0.7008,
      "step": 4900
    },
    {
      "epoch": 0.8187661194579768,
      "grad_norm": 0.0012107897782698274,
      "learning_rate": 7.475450311430336e-06,
      "loss": 0.6991,
      "step": 5000
    },
    {
      "epoch": 0.8187661194579768,
      "eval_loss": 0.6929377913475037,
      "eval_runtime": 303.1385,
      "eval_samples_per_second": 20.73,
      "eval_steps_per_second": 5.182,
      "step": 5000
    },
    {
      "epoch": 0.8351414418471363,
      "grad_norm": 0.00232298718765378,
      "learning_rate": 7.419336737556816e-06,
      "loss": 0.7008,
      "step": 5100
    },
    {
      "epoch": 0.8515167642362959,
      "grad_norm": 0.0020035840570926666,
      "learning_rate": 7.363223163683295e-06,
      "loss": 0.6997,
      "step": 5200
    },
    {
      "epoch": 0.8678920866254555,
      "grad_norm": 0.010045233182609081,
      "learning_rate": 7.307109589809775e-06,
      "loss": 0.6997,
      "step": 5300
    },
    {
      "epoch": 0.884267409014615,
      "grad_norm": 0.005091596860438585,
      "learning_rate": 7.250996015936256e-06,
      "loss": 0.6991,
      "step": 5400
    },
    {
      "epoch": 0.9006427314037745,
      "grad_norm": 0.001718144747428596,
      "learning_rate": 7.194882442062736e-06,
      "loss": 0.7008,
      "step": 5500
    },
    {
      "epoch": 0.9006427314037745,
      "eval_loss": 0.6929175853729248,
      "eval_runtime": 300.87,
      "eval_samples_per_second": 20.886,
      "eval_steps_per_second": 5.222,
      "step": 5500
    },
    {
      "epoch": 0.917018053792934,
      "grad_norm": 0.0011715651489794254,
      "learning_rate": 7.138768868189216e-06,
      "loss": 0.7002,
      "step": 5600
    },
    {
      "epoch": 0.9333933761820936,
      "grad_norm": 0.004972199909389019,
      "learning_rate": 7.082655294315696e-06,
      "loss": 0.6981,
      "step": 5700
    },
    {
      "epoch": 0.9497686985712531,
      "grad_norm": 0.0014733498683199286,
      "learning_rate": 7.026541720442176e-06,
      "loss": 0.6997,
      "step": 5800
    },
    {
      "epoch": 0.9661440209604126,
      "grad_norm": 0.0010651913471519947,
      "learning_rate": 6.970428146568655e-06,
      "loss": 0.7008,
      "step": 5900
    },
    {
      "epoch": 0.9825193433495722,
      "grad_norm": 0.0027340794913470745,
      "learning_rate": 6.914314572695135e-06,
      "loss": 0.6991,
      "step": 6000
    },
    {
      "epoch": 0.9825193433495722,
      "eval_loss": 0.6928665637969971,
      "eval_runtime": 298.843,
      "eval_samples_per_second": 21.028,
      "eval_steps_per_second": 5.257,
      "step": 6000
    },
    {
      "epoch": 0.9988946657387318,
      "grad_norm": 0.0022811221424490213,
      "learning_rate": 6.8582009988216155e-06,
      "loss": 0.7002,
      "step": 6100
    },
    {
      "epoch": 1.0152290498219183,
      "grad_norm": 0.0007365942001342773,
      "learning_rate": 6.802087424948095e-06,
      "loss": 0.6968,
      "step": 6200
    },
    {
      "epoch": 1.031604372211078,
      "grad_norm": 0.0017747366800904274,
      "learning_rate": 6.745973851074576e-06,
      "loss": 0.698,
      "step": 6300
    },
    {
      "epoch": 1.0479796946002375,
      "grad_norm": 0.0011553862132132053,
      "learning_rate": 6.689860277201056e-06,
      "loss": 0.7002,
      "step": 6400
    },
    {
      "epoch": 1.064355016989397,
      "grad_norm": 0.0019851927645504475,
      "learning_rate": 6.633746703327536e-06,
      "loss": 0.6985,
      "step": 6500
    },
    {
      "epoch": 1.064355016989397,
      "eval_loss": 0.6928649544715881,
      "eval_runtime": 297.7007,
      "eval_samples_per_second": 21.108,
      "eval_steps_per_second": 5.277,
      "step": 6500
    },
    {
      "epoch": 1.0807303393785566,
      "grad_norm": 0.001539349090307951,
      "learning_rate": 6.577633129454015e-06,
      "loss": 0.6985,
      "step": 6600
    },
    {
      "epoch": 1.097105661767716,
      "grad_norm": 0.004771040286868811,
      "learning_rate": 6.5215195555804954e-06,
      "loss": 0.6996,
      "step": 6700
    },
    {
      "epoch": 1.1134809841568756,
      "grad_norm": 0.0012187209213152528,
      "learning_rate": 6.465405981706976e-06,
      "loss": 0.6997,
      "step": 6800
    },
    {
      "epoch": 1.1298563065460352,
      "grad_norm": 0.0010833906708285213,
      "learning_rate": 6.409292407833455e-06,
      "loss": 0.6991,
      "step": 6900
    },
    {
      "epoch": 1.1462316289351946,
      "grad_norm": 0.0005937528912909329,
      "learning_rate": 6.353178833959935e-06,
      "loss": 0.7002,
      "step": 7000
    },
    {
      "epoch": 1.1462316289351946,
      "eval_loss": 0.6928516030311584,
      "eval_runtime": 297.3678,
      "eval_samples_per_second": 21.132,
      "eval_steps_per_second": 5.283,
      "step": 7000
    },
    {
      "epoch": 1.1626069513243542,
      "grad_norm": 0.00048177363350987434,
      "learning_rate": 6.297065260086416e-06,
      "loss": 0.6996,
      "step": 7100
    },
    {
      "epoch": 1.1789822737135138,
      "grad_norm": 0.0010940394131466746,
      "learning_rate": 6.240951686212895e-06,
      "loss": 0.7008,
      "step": 7200
    },
    {
      "epoch": 1.1953575961026732,
      "grad_norm": 0.0009761542314663529,
      "learning_rate": 6.1848381123393754e-06,
      "loss": 0.7007,
      "step": 7300
    },
    {
      "epoch": 1.2117329184918328,
      "grad_norm": 0.0017500279936939478,
      "learning_rate": 6.1287245384658556e-06,
      "loss": 0.7013,
      "step": 7400
    },
    {
      "epoch": 1.2281082408809922,
      "grad_norm": 0.000668576278258115,
      "learning_rate": 6.072610964592336e-06,
      "loss": 0.6979,
      "step": 7500
    },
    {
      "epoch": 1.2281082408809922,
      "eval_loss": 0.6928449869155884,
      "eval_runtime": 297.7556,
      "eval_samples_per_second": 21.105,
      "eval_steps_per_second": 5.276,
      "step": 7500
    },
    {
      "epoch": 1.2444835632701519,
      "grad_norm": 0.0007577263750135899,
      "learning_rate": 6.016497390718815e-06,
      "loss": 0.6979,
      "step": 7600
    },
    {
      "epoch": 1.2608588856593115,
      "grad_norm": 0.0020427440758794546,
      "learning_rate": 5.960383816845295e-06,
      "loss": 0.6996,
      "step": 7700
    },
    {
      "epoch": 1.2772342080484709,
      "grad_norm": 0.0010992494644597173,
      "learning_rate": 5.904270242971776e-06,
      "loss": 0.6979,
      "step": 7800
    },
    {
      "epoch": 1.2936095304376305,
      "grad_norm": 0.0007066844264045358,
      "learning_rate": 5.8481566690982546e-06,
      "loss": 0.6996,
      "step": 7900
    },
    {
      "epoch": 1.3099848528267901,
      "grad_norm": 0.0007107537239789963,
      "learning_rate": 5.7920430952247356e-06,
      "loss": 0.6979,
      "step": 8000
    },
    {
      "epoch": 1.3099848528267901,
      "eval_loss": 0.6928384304046631,
      "eval_runtime": 299.8232,
      "eval_samples_per_second": 20.959,
      "eval_steps_per_second": 5.24,
      "step": 8000
    },
    {
      "epoch": 1.3263601752159495,
      "grad_norm": 0.0015347093576565385,
      "learning_rate": 5.735929521351216e-06,
      "loss": 0.6968,
      "step": 8100
    },
    {
      "epoch": 1.3427354976051091,
      "grad_norm": 0.0003353393403813243,
      "learning_rate": 5.679815947477695e-06,
      "loss": 0.6996,
      "step": 8200
    },
    {
      "epoch": 1.3591108199942687,
      "grad_norm": 0.0035431135911494493,
      "learning_rate": 5.623702373604175e-06,
      "loss": 0.7013,
      "step": 8300
    },
    {
      "epoch": 1.3754861423834281,
      "grad_norm": 0.0009145435178652406,
      "learning_rate": 5.567588799730655e-06,
      "loss": 0.6996,
      "step": 8400
    },
    {
      "epoch": 1.3918614647725878,
      "grad_norm": 0.0005753137520514429,
      "learning_rate": 5.511475225857135e-06,
      "loss": 0.6979,
      "step": 8500
    },
    {
      "epoch": 1.3918614647725878,
      "eval_loss": 0.6928344964981079,
      "eval_runtime": 298.7813,
      "eval_samples_per_second": 21.032,
      "eval_steps_per_second": 5.258,
      "step": 8500
    },
    {
      "epoch": 1.4082367871617474,
      "grad_norm": 0.0004708111518993974,
      "learning_rate": 5.455361651983615e-06,
      "loss": 0.6985,
      "step": 8600
    },
    {
      "epoch": 1.4246121095509068,
      "grad_norm": 0.0003316659713163972,
      "learning_rate": 5.399248078110096e-06,
      "loss": 0.7002,
      "step": 8700
    },
    {
      "epoch": 1.4409874319400664,
      "grad_norm": 0.0009513390250504017,
      "learning_rate": 5.343134504236576e-06,
      "loss": 0.7013,
      "step": 8800
    },
    {
      "epoch": 1.4573627543292258,
      "grad_norm": 0.000634260184597224,
      "learning_rate": 5.287020930363055e-06,
      "loss": 0.699,
      "step": 8900
    },
    {
      "epoch": 1.4737380767183854,
      "grad_norm": 0.0014602559385821223,
      "learning_rate": 5.230907356489535e-06,
      "loss": 0.7007,
      "step": 9000
    },
    {
      "epoch": 1.4737380767183854,
      "eval_loss": 0.692829430103302,
      "eval_runtime": 299.1097,
      "eval_samples_per_second": 21.009,
      "eval_steps_per_second": 5.252,
      "step": 9000
    },
    {
      "epoch": 1.4901133991075448,
      "grad_norm": 0.0007322909077629447,
      "learning_rate": 5.174793782616015e-06,
      "loss": 0.7007,
      "step": 9100
    },
    {
      "epoch": 1.5064887214967044,
      "grad_norm": 0.0002963577280752361,
      "learning_rate": 5.118680208742495e-06,
      "loss": 0.6979,
      "step": 9200
    },
    {
      "epoch": 1.522864043885864,
      "grad_norm": 0.0002055245713563636,
      "learning_rate": 5.062566634868975e-06,
      "loss": 0.6979,
      "step": 9300
    },
    {
      "epoch": 1.5392393662750234,
      "grad_norm": 0.00029846769757568836,
      "learning_rate": 5.006453060995455e-06,
      "loss": 0.7002,
      "step": 9400
    },
    {
      "epoch": 1.555614688664183,
      "grad_norm": 0.00033199903555214405,
      "learning_rate": 4.950339487121935e-06,
      "loss": 0.6985,
      "step": 9500
    },
    {
      "epoch": 1.555614688664183,
      "eval_loss": 0.6928284168243408,
      "eval_runtime": 311.5741,
      "eval_samples_per_second": 20.169,
      "eval_steps_per_second": 5.042,
      "step": 9500
    },
    {
      "epoch": 1.5719900110533427,
      "grad_norm": 0.0004713107191491872,
      "learning_rate": 4.894225913248415e-06,
      "loss": 0.6996,
      "step": 9600
    },
    {
      "epoch": 1.588365333442502,
      "grad_norm": 0.0005716572050005198,
      "learning_rate": 4.838112339374895e-06,
      "loss": 0.7002,
      "step": 9700
    },
    {
      "epoch": 1.6047406558316617,
      "grad_norm": 0.009176289662718773,
      "learning_rate": 4.781998765501375e-06,
      "loss": 0.6997,
      "step": 9800
    },
    {
      "epoch": 1.6211159782208213,
      "grad_norm": 0.00026015154435299337,
      "learning_rate": 4.725885191627856e-06,
      "loss": 0.6985,
      "step": 9900
    },
    {
      "epoch": 1.6374913006099807,
      "grad_norm": 0.0003567319654393941,
      "learning_rate": 4.669771617754335e-06,
      "loss": 0.6996,
      "step": 10000
    },
    {
      "epoch": 1.6374913006099807,
      "eval_loss": 0.6928249597549438,
      "eval_runtime": 299.1989,
      "eval_samples_per_second": 21.003,
      "eval_steps_per_second": 5.251,
      "step": 10000
    },
    {
      "epoch": 1.6538666229991403,
      "grad_norm": 0.0006316765793599188,
      "learning_rate": 4.613658043880815e-06,
      "loss": 0.6996,
      "step": 10100
    },
    {
      "epoch": 1.6702419453883,
      "grad_norm": 0.00058352155610919,
      "learning_rate": 4.557544470007295e-06,
      "loss": 0.6996,
      "step": 10200
    },
    {
      "epoch": 1.6866172677774594,
      "grad_norm": 0.000268969452008605,
      "learning_rate": 4.5014308961337745e-06,
      "loss": 0.7007,
      "step": 10300
    },
    {
      "epoch": 1.7029925901666187,
      "grad_norm": 0.0011197022395208478,
      "learning_rate": 4.4453173222602555e-06,
      "loss": 0.7002,
      "step": 10400
    },
    {
      "epoch": 1.7193679125557786,
      "grad_norm": 0.0004742988967336714,
      "learning_rate": 4.389203748386735e-06,
      "loss": 0.699,
      "step": 10500
    },
    {
      "epoch": 1.7193679125557786,
      "eval_loss": 0.6928226351737976,
      "eval_runtime": 299.2096,
      "eval_samples_per_second": 21.002,
      "eval_steps_per_second": 5.25,
      "step": 10500
    },
    {
      "epoch": 1.735743234944938,
      "grad_norm": 0.00046192712034098804,
      "learning_rate": 4.333090174513215e-06,
      "loss": 0.699,
      "step": 10600
    },
    {
      "epoch": 1.7521185573340974,
      "grad_norm": 0.0003493016411084682,
      "learning_rate": 4.276976600639695e-06,
      "loss": 0.7007,
      "step": 10700
    },
    {
      "epoch": 1.768493879723257,
      "grad_norm": 0.00012397060345392674,
      "learning_rate": 4.220863026766175e-06,
      "loss": 0.6985,
      "step": 10800
    },
    {
      "epoch": 1.7848692021124166,
      "grad_norm": 0.0002126398467225954,
      "learning_rate": 4.164749452892655e-06,
      "loss": 0.6974,
      "step": 10900
    },
    {
      "epoch": 1.801244524501576,
      "grad_norm": 0.00023344568035099655,
      "learning_rate": 4.108635879019135e-06,
      "loss": 0.7007,
      "step": 11000
    },
    {
      "epoch": 1.801244524501576,
      "eval_loss": 0.6928215026855469,
      "eval_runtime": 305.4586,
      "eval_samples_per_second": 20.572,
      "eval_steps_per_second": 5.143,
      "step": 11000
    },
    {
      "epoch": 1.8176198468907356,
      "grad_norm": 0.00021714488684665412,
      "learning_rate": 4.052522305145616e-06,
      "loss": 0.699,
      "step": 11100
    },
    {
      "epoch": 1.8339951692798953,
      "grad_norm": 0.00020476059580687433,
      "learning_rate": 3.996408731272095e-06,
      "loss": 0.7007,
      "step": 11200
    },
    {
      "epoch": 1.8503704916690547,
      "grad_norm": 0.00028312590438872576,
      "learning_rate": 3.940295157398575e-06,
      "loss": 0.6996,
      "step": 11300
    },
    {
      "epoch": 1.8667458140582143,
      "grad_norm": 0.0004353972035460174,
      "learning_rate": 3.884181583525055e-06,
      "loss": 0.6996,
      "step": 11400
    },
    {
      "epoch": 1.8831211364473739,
      "grad_norm": 0.0010558903450146317,
      "learning_rate": 3.8280680096515345e-06,
      "loss": 0.6996,
      "step": 11500
    },
    {
      "epoch": 1.8831211364473739,
      "eval_loss": 0.6928198337554932,
      "eval_runtime": 298.0046,
      "eval_samples_per_second": 21.087,
      "eval_steps_per_second": 5.272,
      "step": 11500
    },
    {
      "epoch": 1.8994964588365333,
      "grad_norm": 0.00040714535862207413,
      "learning_rate": 3.771954435778015e-06,
      "loss": 0.7007,
      "step": 11600
    },
    {
      "epoch": 1.915871781225693,
      "grad_norm": 0.00011803150846390054,
      "learning_rate": 3.715840861904495e-06,
      "loss": 0.7002,
      "step": 11700
    },
    {
      "epoch": 1.9322471036148525,
      "grad_norm": 0.00017203958122991025,
      "learning_rate": 3.659727288030975e-06,
      "loss": 0.6974,
      "step": 11800
    },
    {
      "epoch": 1.948622426004012,
      "grad_norm": 0.00019382227037567645,
      "learning_rate": 3.603613714157455e-06,
      "loss": 0.7002,
      "step": 11900
    },
    {
      "epoch": 1.9649977483931715,
      "grad_norm": 0.0005559142446145415,
      "learning_rate": 3.5475001402839348e-06,
      "loss": 0.7002,
      "step": 12000
    },
    {
      "epoch": 1.9649977483931715,
      "eval_loss": 0.6928207278251648,
      "eval_runtime": 298.3497,
      "eval_samples_per_second": 21.063,
      "eval_steps_per_second": 5.266,
      "step": 12000
    },
    {
      "epoch": 1.9813730707823312,
      "grad_norm": 0.00024714297614991665,
      "learning_rate": 3.4913865664104153e-06,
      "loss": 0.699,
      "step": 12100
    },
    {
      "epoch": 1.9977483931714906,
      "grad_norm": 0.000277935789199546,
      "learning_rate": 3.435272992536895e-06,
      "loss": 0.7002,
      "step": 12200
    },
    {
      "epoch": 2.014082777254677,
      "grad_norm": 0.0001456599129596725,
      "learning_rate": 3.3791594186633748e-06,
      "loss": 0.6967,
      "step": 12300
    },
    {
      "epoch": 2.0304580996438366,
      "grad_norm": 7.856247248128057e-05,
      "learning_rate": 3.323045844789855e-06,
      "loss": 0.6979,
      "step": 12400
    },
    {
      "epoch": 2.0468334220329965,
      "grad_norm": 0.0003776526136789471,
      "learning_rate": 3.2669322709163346e-06,
      "loss": 0.7002,
      "step": 12500
    },
    {
      "epoch": 2.0468334220329965,
      "eval_loss": 0.6928178071975708,
      "eval_runtime": 299.6518,
      "eval_samples_per_second": 20.971,
      "eval_steps_per_second": 5.243,
      "step": 12500
    },
    {
      "epoch": 2.063208744422156,
      "grad_norm": 0.0001924554380821064,
      "learning_rate": 3.210818697042815e-06,
      "loss": 0.6996,
      "step": 12600
    },
    {
      "epoch": 2.0795840668113152,
      "grad_norm": 0.00017826055409386754,
      "learning_rate": 3.154705123169295e-06,
      "loss": 0.6974,
      "step": 12700
    },
    {
      "epoch": 2.095959389200475,
      "grad_norm": 0.00012395773956086487,
      "learning_rate": 3.0985915492957746e-06,
      "loss": 0.6996,
      "step": 12800
    },
    {
      "epoch": 2.1123347115896345,
      "grad_norm": 0.00014498966629616916,
      "learning_rate": 3.042477975422255e-06,
      "loss": 0.7002,
      "step": 12900
    },
    {
      "epoch": 2.128710033978794,
      "grad_norm": 9.848795889411122e-05,
      "learning_rate": 2.986364401548735e-06,
      "loss": 0.699,
      "step": 13000
    },
    {
      "epoch": 2.128710033978794,
      "eval_loss": 0.6928176879882812,
      "eval_runtime": 302.6169,
      "eval_samples_per_second": 20.766,
      "eval_steps_per_second": 5.191,
      "step": 13000
    },
    {
      "epoch": 2.1450853563679537,
      "grad_norm": 9.474238322582096e-05,
      "learning_rate": 2.930250827675215e-06,
      "loss": 0.6996,
      "step": 13100
    },
    {
      "epoch": 2.161460678757113,
      "grad_norm": 0.00016408534429501742,
      "learning_rate": 2.8741372538016947e-06,
      "loss": 0.6996,
      "step": 13200
    },
    {
      "epoch": 2.1778360011462725,
      "grad_norm": 0.0002357933553867042,
      "learning_rate": 2.8180236799281745e-06,
      "loss": 0.7007,
      "step": 13300
    },
    {
      "epoch": 2.194211323535432,
      "grad_norm": 0.00014000324881635606,
      "learning_rate": 2.761910106054655e-06,
      "loss": 0.7007,
      "step": 13400
    },
    {
      "epoch": 2.2105866459245918,
      "grad_norm": 0.00025381133309565485,
      "learning_rate": 2.7057965321811347e-06,
      "loss": 0.7013,
      "step": 13500
    },
    {
      "epoch": 2.2105866459245918,
      "eval_loss": 0.6928166747093201,
      "eval_runtime": 298.4659,
      "eval_samples_per_second": 21.054,
      "eval_steps_per_second": 5.264,
      "step": 13500
    },
    {
      "epoch": 2.226961968313751,
      "grad_norm": 7.786534843035042e-05,
      "learning_rate": 2.649682958307615e-06,
      "loss": 0.6985,
      "step": 13600
    },
    {
      "epoch": 2.2433372907029105,
      "grad_norm": 0.00011840831575682387,
      "learning_rate": 2.5935693844340946e-06,
      "loss": 0.6973,
      "step": 13700
    },
    {
      "epoch": 2.2597126130920704,
      "grad_norm": 0.0001570479362271726,
      "learning_rate": 2.5374558105605747e-06,
      "loss": 0.6996,
      "step": 13800
    },
    {
      "epoch": 2.27608793548123,
      "grad_norm": 0.00010547442798269913,
      "learning_rate": 2.481342236687055e-06,
      "loss": 0.699,
      "step": 13900
    },
    {
      "epoch": 2.292463257870389,
      "grad_norm": 9.591737762093544e-05,
      "learning_rate": 2.425228662813535e-06,
      "loss": 0.6985,
      "step": 14000
    },
    {
      "epoch": 2.292463257870389,
      "eval_loss": 0.6928160786628723,
      "eval_runtime": 297.4121,
      "eval_samples_per_second": 21.129,
      "eval_steps_per_second": 5.282,
      "step": 14000
    },
    {
      "epoch": 2.308838580259549,
      "grad_norm": 9.407267498318106e-05,
      "learning_rate": 2.3691150889400147e-06,
      "loss": 0.6985,
      "step": 14100
    },
    {
      "epoch": 2.3252139026487084,
      "grad_norm": 6.0649595980066806e-05,
      "learning_rate": 2.313001515066495e-06,
      "loss": 0.6968,
      "step": 14200
    },
    {
      "epoch": 2.341589225037868,
      "grad_norm": 0.00014282924530562013,
      "learning_rate": 2.2568879411929746e-06,
      "loss": 0.6996,
      "step": 14300
    },
    {
      "epoch": 2.3579645474270277,
      "grad_norm": 0.0001583010161994025,
      "learning_rate": 2.2007743673194547e-06,
      "loss": 0.7013,
      "step": 14400
    },
    {
      "epoch": 2.374339869816187,
      "grad_norm": 0.00022402498871088028,
      "learning_rate": 2.144660793445935e-06,
      "loss": 0.699,
      "step": 14500
    },
    {
      "epoch": 2.374339869816187,
      "eval_loss": 0.6928156018257141,
      "eval_runtime": 300.6147,
      "eval_samples_per_second": 20.904,
      "eval_steps_per_second": 5.226,
      "step": 14500
    },
    {
      "epoch": 2.3907151922053465,
      "grad_norm": 0.00040772149804979563,
      "learning_rate": 2.0885472195724146e-06,
      "loss": 0.6985,
      "step": 14600
    },
    {
      "epoch": 2.407090514594506,
      "grad_norm": 9.812293865252286e-05,
      "learning_rate": 2.0324336456988947e-06,
      "loss": 0.699,
      "step": 14700
    },
    {
      "epoch": 2.4234658369836657,
      "grad_norm": 0.00013346913328859955,
      "learning_rate": 1.976320071825375e-06,
      "loss": 0.6996,
      "step": 14800
    },
    {
      "epoch": 2.439841159372825,
      "grad_norm": 0.0002251446567242965,
      "learning_rate": 1.9202064979518546e-06,
      "loss": 0.7007,
      "step": 14900
    },
    {
      "epoch": 2.4562164817619845,
      "grad_norm": 7.028323307167739e-05,
      "learning_rate": 1.864092924078335e-06,
      "loss": 0.699,
      "step": 15000
    },
    {
      "epoch": 2.4562164817619845,
      "eval_loss": 0.6928154826164246,
      "eval_runtime": 297.6903,
      "eval_samples_per_second": 21.109,
      "eval_steps_per_second": 5.277,
      "step": 15000
    },
    {
      "epoch": 2.4725918041511443,
      "grad_norm": 0.00019666572916321456,
      "learning_rate": 1.8079793502048146e-06,
      "loss": 0.7007,
      "step": 15100
    },
    {
      "epoch": 2.4889671265403037,
      "grad_norm": 0.00014007270510774106,
      "learning_rate": 1.7518657763312946e-06,
      "loss": 0.7007,
      "step": 15200
    },
    {
      "epoch": 2.505342448929463,
      "grad_norm": 7.641380216227844e-05,
      "learning_rate": 1.6957522024577747e-06,
      "loss": 0.6979,
      "step": 15300
    },
    {
      "epoch": 2.521717771318623,
      "grad_norm": 3.056827335967682e-05,
      "learning_rate": 1.6396386285842546e-06,
      "loss": 0.6979,
      "step": 15400
    },
    {
      "epoch": 2.5380930937077824,
      "grad_norm": 8.465444261673838e-05,
      "learning_rate": 1.5835250547107348e-06,
      "loss": 0.7002,
      "step": 15500
    },
    {
      "epoch": 2.5380930937077824,
      "eval_loss": 0.6928148865699768,
      "eval_runtime": 298.1181,
      "eval_samples_per_second": 21.079,
      "eval_steps_per_second": 5.27,
      "step": 15500
    },
    {
      "epoch": 2.5544684160969418,
      "grad_norm": 0.0003877301060128957,
      "learning_rate": 1.5274114808372145e-06,
      "loss": 0.6985,
      "step": 15600
    },
    {
      "epoch": 2.5708437384861016,
      "grad_norm": 0.00025587479467503726,
      "learning_rate": 1.4712979069636946e-06,
      "loss": 0.7002,
      "step": 15700
    },
    {
      "epoch": 2.587219060875261,
      "grad_norm": 0.0012030979851260781,
      "learning_rate": 1.4151843330901745e-06,
      "loss": 0.6996,
      "step": 15800
    },
    {
      "epoch": 2.6035943832644204,
      "grad_norm": 0.00022968398116063327,
      "learning_rate": 1.3590707592166547e-06,
      "loss": 0.6996,
      "step": 15900
    },
    {
      "epoch": 2.6199697056535802,
      "grad_norm": 0.00015052559319883585,
      "learning_rate": 1.3029571853431346e-06,
      "loss": 0.6985,
      "step": 16000
    },
    {
      "epoch": 2.6199697056535802,
      "eval_loss": 0.6928147673606873,
      "eval_runtime": 297.829,
      "eval_samples_per_second": 21.099,
      "eval_steps_per_second": 5.275,
      "step": 16000
    },
    {
      "epoch": 2.6363450280427396,
      "grad_norm": 5.470675023389049e-05,
      "learning_rate": 1.2468436114696145e-06,
      "loss": 0.7002,
      "step": 16100
    },
    {
      "epoch": 2.652720350431899,
      "grad_norm": 3.338248279760592e-05,
      "learning_rate": 1.1907300375960947e-06,
      "loss": 0.699,
      "step": 16200
    },
    {
      "epoch": 2.669095672821059,
      "grad_norm": 0.00011908244778169319,
      "learning_rate": 1.1346164637225746e-06,
      "loss": 0.7002,
      "step": 16300
    },
    {
      "epoch": 2.6854709952102183,
      "grad_norm": 4.348035508883186e-05,
      "learning_rate": 1.0785028898490545e-06,
      "loss": 0.7002,
      "step": 16400
    },
    {
      "epoch": 2.7018463175993777,
      "grad_norm": 9.64790306170471e-05,
      "learning_rate": 1.0223893159755345e-06,
      "loss": 0.7002,
      "step": 16500
    },
    {
      "epoch": 2.7018463175993777,
      "eval_loss": 0.6928144693374634,
      "eval_runtime": 305.1736,
      "eval_samples_per_second": 20.592,
      "eval_steps_per_second": 5.148,
      "step": 16500
    },
    {
      "epoch": 2.7182216399885375,
      "grad_norm": 8.071588672464713e-05,
      "learning_rate": 9.662757421020146e-07,
      "loss": 0.699,
      "step": 16600
    },
    {
      "epoch": 2.734596962377697,
      "grad_norm": 0.00020182672597002238,
      "learning_rate": 9.101621682284946e-07,
      "loss": 0.699,
      "step": 16700
    },
    {
      "epoch": 2.7509722847668563,
      "grad_norm": 3.509279849822633e-05,
      "learning_rate": 8.540485943549746e-07,
      "loss": 0.7007,
      "step": 16800
    },
    {
      "epoch": 2.767347607156016,
      "grad_norm": 3.2761112379375845e-05,
      "learning_rate": 7.979350204814546e-07,
      "loss": 0.6985,
      "step": 16900
    },
    {
      "epoch": 2.7837229295451755,
      "grad_norm": 0.00011736930173356086,
      "learning_rate": 7.418214466079344e-07,
      "loss": 0.6973,
      "step": 17000
    },
    {
      "epoch": 2.7837229295451755,
      "eval_loss": 0.6928143501281738,
      "eval_runtime": 298.8319,
      "eval_samples_per_second": 21.029,
      "eval_steps_per_second": 5.257,
      "step": 17000
    },
    {
      "epoch": 2.800098251934335,
      "grad_norm": 0.00011321976489853114,
      "learning_rate": 6.857078727344145e-07,
      "loss": 0.7007,
      "step": 17100
    },
    {
      "epoch": 2.8164735743234948,
      "grad_norm": 4.6627610572613776e-05,
      "learning_rate": 6.295942988608946e-07,
      "loss": 0.699,
      "step": 17200
    },
    {
      "epoch": 2.832848896712654,
      "grad_norm": 6.852613296359777e-05,
      "learning_rate": 5.734807249873745e-07,
      "loss": 0.7013,
      "step": 17300
    },
    {
      "epoch": 2.8492242191018136,
      "grad_norm": 5.4399708460550755e-05,
      "learning_rate": 5.173671511138545e-07,
      "loss": 0.6996,
      "step": 17400
    },
    {
      "epoch": 2.865599541490973,
      "grad_norm": 8.749964035814628e-05,
      "learning_rate": 4.6125357724033446e-07,
      "loss": 0.699,
      "step": 17500
    },
    {
      "epoch": 2.865599541490973,
      "eval_loss": 0.6928143501281738,
      "eval_runtime": 302.4597,
      "eval_samples_per_second": 20.776,
      "eval_steps_per_second": 5.194,
      "step": 17500
    },
    {
      "epoch": 2.881974863880133,
      "grad_norm": 2.6403415176901035e-05,
      "learning_rate": 4.0514000336681444e-07,
      "loss": 0.6996,
      "step": 17600
    },
    {
      "epoch": 2.898350186269292,
      "grad_norm": 7.15201604180038e-05,
      "learning_rate": 3.490264294932945e-07,
      "loss": 0.7007,
      "step": 17700
    },
    {
      "epoch": 2.9147255086584516,
      "grad_norm": 5.031650289311074e-05,
      "learning_rate": 2.9291285561977446e-07,
      "loss": 0.7002,
      "step": 17800
    },
    {
      "epoch": 2.931100831047611,
      "grad_norm": 2.4922110242187046e-05,
      "learning_rate": 2.3679928174625444e-07,
      "loss": 0.6979,
      "step": 17900
    },
    {
      "epoch": 2.947476153436771,
      "grad_norm": 6.712684262311086e-05,
      "learning_rate": 1.8068570787273442e-07,
      "loss": 0.6996,
      "step": 18000
    },
    {
      "epoch": 2.947476153436771,
      "eval_loss": 0.6928142309188843,
      "eval_runtime": 303.3566,
      "eval_samples_per_second": 20.715,
      "eval_steps_per_second": 5.179,
      "step": 18000
    }
  ],
  "logging_steps": 100,
  "max_steps": 18321,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
