{
  "best_global_step": 4000,
  "best_metric": 0.7081717848777771,
  "best_model_checkpoint": "/data3/gkook/temp/agi/canary-qwen-2.5b_ft_result_v3/checkpoint-4000",
  "epoch": 3.2788599548903012,
  "eval_steps": 500,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08201763379126512,
      "grad_norm": 1.8442542552947998,
      "learning_rate": 1.98e-06,
      "loss": 7.6247,
      "step": 100
    },
    {
      "epoch": 0.16403526758253023,
      "grad_norm": 2.311546802520752,
      "learning_rate": 3.980000000000001e-06,
      "loss": 7.5629,
      "step": 200
    },
    {
      "epoch": 0.24605290137379537,
      "grad_norm": 2.929640531539917,
      "learning_rate": 5.98e-06,
      "loss": 7.2596,
      "step": 300
    },
    {
      "epoch": 0.32807053516506046,
      "grad_norm": 3.932894706726074,
      "learning_rate": 7.980000000000002e-06,
      "loss": 6.5944,
      "step": 400
    },
    {
      "epoch": 0.4100881689563256,
      "grad_norm": 3.5148777961730957,
      "learning_rate": 9.980000000000001e-06,
      "loss": 5.3823,
      "step": 500
    },
    {
      "epoch": 0.4100881689563256,
      "eval_loss": 5.063215255737305,
      "eval_runtime": 212.6602,
      "eval_samples_per_second": 29.549,
      "eval_steps_per_second": 7.387,
      "step": 500
    },
    {
      "epoch": 0.49210580274759075,
      "grad_norm": 3.339183807373047,
      "learning_rate": 9.823214285714287e-06,
      "loss": 3.9551,
      "step": 600
    },
    {
      "epoch": 0.5741234365388559,
      "grad_norm": 1.7593880891799927,
      "learning_rate": 9.644642857142857e-06,
      "loss": 2.9955,
      "step": 700
    },
    {
      "epoch": 0.6561410703301209,
      "grad_norm": 2.4745612144470215,
      "learning_rate": 9.466071428571429e-06,
      "loss": 2.649,
      "step": 800
    },
    {
      "epoch": 0.7381587041213861,
      "grad_norm": 3.0725080966949463,
      "learning_rate": 9.2875e-06,
      "loss": 2.2573,
      "step": 900
    },
    {
      "epoch": 0.8201763379126512,
      "grad_norm": 0.553197979927063,
      "learning_rate": 9.108928571428572e-06,
      "loss": 1.6832,
      "step": 1000
    },
    {
      "epoch": 0.8201763379126512,
      "eval_loss": 1.6023281812667847,
      "eval_runtime": 212.307,
      "eval_samples_per_second": 29.599,
      "eval_steps_per_second": 7.4,
      "step": 1000
    },
    {
      "epoch": 0.9021939717039164,
      "grad_norm": 0.6343781352043152,
      "learning_rate": 8.930357142857144e-06,
      "loss": 1.4558,
      "step": 1100
    },
    {
      "epoch": 0.9842116054951815,
      "grad_norm": 0.7920990586280823,
      "learning_rate": 8.751785714285715e-06,
      "loss": 1.3999,
      "step": 1200
    },
    {
      "epoch": 1.065614107033012,
      "grad_norm": 0.9543387293815613,
      "learning_rate": 8.573214285714287e-06,
      "loss": 1.3362,
      "step": 1300
    },
    {
      "epoch": 1.147631740824277,
      "grad_norm": 1.1590055227279663,
      "learning_rate": 8.394642857142857e-06,
      "loss": 1.272,
      "step": 1400
    },
    {
      "epoch": 1.2296493746155424,
      "grad_norm": 1.8884838819503784,
      "learning_rate": 8.216071428571429e-06,
      "loss": 1.1694,
      "step": 1500
    },
    {
      "epoch": 1.2296493746155424,
      "eval_loss": 1.170566201210022,
      "eval_runtime": 213.1423,
      "eval_samples_per_second": 29.483,
      "eval_steps_per_second": 7.371,
      "step": 1500
    },
    {
      "epoch": 1.3116670084068074,
      "grad_norm": 0.580805242061615,
      "learning_rate": 8.0375e-06,
      "loss": 0.9064,
      "step": 1600
    },
    {
      "epoch": 1.3936846421980726,
      "grad_norm": 0.10256122797727585,
      "learning_rate": 7.858928571428572e-06,
      "loss": 0.6976,
      "step": 1700
    },
    {
      "epoch": 1.4757022759893377,
      "grad_norm": 0.04727468267083168,
      "learning_rate": 7.680357142857144e-06,
      "loss": 0.6886,
      "step": 1800
    },
    {
      "epoch": 1.557719909780603,
      "grad_norm": 0.09688807278871536,
      "learning_rate": 7.501785714285716e-06,
      "loss": 0.6928,
      "step": 1900
    },
    {
      "epoch": 1.639737543571868,
      "grad_norm": 0.029716692864894867,
      "learning_rate": 7.3232142857142864e-06,
      "loss": 0.6854,
      "step": 2000
    },
    {
      "epoch": 1.639737543571868,
      "eval_loss": 0.8081202507019043,
      "eval_runtime": 211.6921,
      "eval_samples_per_second": 29.685,
      "eval_steps_per_second": 7.421,
      "step": 2000
    },
    {
      "epoch": 1.721755177363133,
      "grad_norm": 0.026964476332068443,
      "learning_rate": 7.144642857142857e-06,
      "loss": 0.6875,
      "step": 2100
    },
    {
      "epoch": 1.8037728111543982,
      "grad_norm": 0.026038626208901405,
      "learning_rate": 6.966071428571429e-06,
      "loss": 0.6861,
      "step": 2200
    },
    {
      "epoch": 1.8857904449456633,
      "grad_norm": 0.0339941643178463,
      "learning_rate": 6.7875e-06,
      "loss": 0.6837,
      "step": 2300
    },
    {
      "epoch": 1.9678080787369283,
      "grad_norm": 0.02581408992409706,
      "learning_rate": 6.608928571428572e-06,
      "loss": 0.6868,
      "step": 2400
    },
    {
      "epoch": 2.049210580274759,
      "grad_norm": 0.01466558501124382,
      "learning_rate": 6.430357142857143e-06,
      "loss": 0.6838,
      "step": 2500
    },
    {
      "epoch": 2.049210580274759,
      "eval_loss": 0.7228410840034485,
      "eval_runtime": 228.0704,
      "eval_samples_per_second": 27.553,
      "eval_steps_per_second": 6.888,
      "step": 2500
    },
    {
      "epoch": 2.131228214066024,
      "grad_norm": 0.02422310598194599,
      "learning_rate": 6.251785714285715e-06,
      "loss": 0.6884,
      "step": 2600
    },
    {
      "epoch": 2.2132458478572894,
      "grad_norm": 0.011529071256518364,
      "learning_rate": 6.0732142857142866e-06,
      "loss": 0.6935,
      "step": 2700
    },
    {
      "epoch": 2.295263481648554,
      "grad_norm": 0.008531344123184681,
      "learning_rate": 5.894642857142857e-06,
      "loss": 0.6889,
      "step": 2800
    },
    {
      "epoch": 2.3772811154398195,
      "grad_norm": 0.009018626995384693,
      "learning_rate": 5.716071428571429e-06,
      "loss": 0.6916,
      "step": 2900
    },
    {
      "epoch": 2.4592987492310847,
      "grad_norm": 0.009312008507549763,
      "learning_rate": 5.5375e-06,
      "loss": 0.686,
      "step": 3000
    },
    {
      "epoch": 2.4592987492310847,
      "eval_loss": 0.8127783536911011,
      "eval_runtime": 211.0708,
      "eval_samples_per_second": 29.772,
      "eval_steps_per_second": 7.443,
      "step": 3000
    },
    {
      "epoch": 2.54131638302235,
      "grad_norm": 0.006989859510213137,
      "learning_rate": 5.3589285714285725e-06,
      "loss": 0.6911,
      "step": 3100
    },
    {
      "epoch": 2.6233340168136148,
      "grad_norm": 0.008094077929854393,
      "learning_rate": 5.180357142857143e-06,
      "loss": 0.6875,
      "step": 3200
    },
    {
      "epoch": 2.70535165060488,
      "grad_norm": 0.006315949838608503,
      "learning_rate": 5.001785714285715e-06,
      "loss": 0.6814,
      "step": 3300
    },
    {
      "epoch": 2.7873692843961453,
      "grad_norm": 0.008509375154972076,
      "learning_rate": 4.823214285714286e-06,
      "loss": 0.6883,
      "step": 3400
    },
    {
      "epoch": 2.86938691818741,
      "grad_norm": 0.009692516177892685,
      "learning_rate": 4.6446428571428575e-06,
      "loss": 0.683,
      "step": 3500
    },
    {
      "epoch": 2.86938691818741,
      "eval_loss": 0.7297253608703613,
      "eval_runtime": 210.023,
      "eval_samples_per_second": 29.921,
      "eval_steps_per_second": 7.48,
      "step": 3500
    },
    {
      "epoch": 2.9514045519786754,
      "grad_norm": 0.005754989106208086,
      "learning_rate": 4.466071428571429e-06,
      "loss": 0.6839,
      "step": 3600
    },
    {
      "epoch": 3.032807053516506,
      "grad_norm": 0.00630323588848114,
      "learning_rate": 4.287500000000001e-06,
      "loss": 0.6856,
      "step": 3700
    },
    {
      "epoch": 3.114824687307771,
      "grad_norm": 0.004301112610846758,
      "learning_rate": 4.108928571428572e-06,
      "loss": 0.6852,
      "step": 3800
    },
    {
      "epoch": 3.1968423210990364,
      "grad_norm": 0.01890520378947258,
      "learning_rate": 3.930357142857143e-06,
      "loss": 0.6937,
      "step": 3900
    },
    {
      "epoch": 3.2788599548903012,
      "grad_norm": 0.007111131213605404,
      "learning_rate": 3.7517857142857147e-06,
      "loss": 0.6886,
      "step": 4000
    },
    {
      "epoch": 3.2788599548903012,
      "eval_loss": 0.7081717848777771,
      "eval_runtime": 216.809,
      "eval_samples_per_second": 28.984,
      "eval_steps_per_second": 7.246,
      "step": 4000
    }
  ],
  "logging_steps": 100,
  "max_steps": 6100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
