{
  "best_global_step": 18000,
  "best_metric": 0.8217898011207581,
  "best_model_checkpoint": "/data3/gkook/temp/agi/canary-qwen-2.5b_ft_result_v2/checkpoint-18000",
  "epoch": 2.947476153436771,
  "eval_steps": 500,
  "global_step": 18000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016375322389159536,
      "grad_norm": 1.317490816116333,
      "learning_rate": 1.98e-06,
      "loss": 5.5552,
      "step": 100
    },
    {
      "epoch": 0.03275064477831907,
      "grad_norm": 1.9086289405822754,
      "learning_rate": 3.980000000000001e-06,
      "loss": 5.5265,
      "step": 200
    },
    {
      "epoch": 0.04912596716747861,
      "grad_norm": 2.6395561695098877,
      "learning_rate": 5.98e-06,
      "loss": 5.3494,
      "step": 300
    },
    {
      "epoch": 0.06550128955663814,
      "grad_norm": 3.543755531311035,
      "learning_rate": 7.980000000000002e-06,
      "loss": 4.8782,
      "step": 400
    },
    {
      "epoch": 0.08187661194579768,
      "grad_norm": 3.8854618072509766,
      "learning_rate": 9.980000000000001e-06,
      "loss": 4.1082,
      "step": 500
    },
    {
      "epoch": 0.08187661194579768,
      "eval_loss": 3.6987099647521973,
      "eval_runtime": 302.8429,
      "eval_samples_per_second": 20.75,
      "eval_steps_per_second": 5.188,
      "step": 500
    },
    {
      "epoch": 0.09825193433495721,
      "grad_norm": 1.9370980262756348,
      "learning_rate": 9.944447561865215e-06,
      "loss": 3.2028,
      "step": 600
    },
    {
      "epoch": 0.11462725672411675,
      "grad_norm": 2.2063775062561035,
      "learning_rate": 9.888333987991696e-06,
      "loss": 2.6153,
      "step": 700
    },
    {
      "epoch": 0.13100257911327629,
      "grad_norm": 2.119191884994507,
      "learning_rate": 9.832220414118176e-06,
      "loss": 2.1871,
      "step": 800
    },
    {
      "epoch": 0.14737790150243582,
      "grad_norm": 0.601473331451416,
      "learning_rate": 9.776106840244655e-06,
      "loss": 1.8379,
      "step": 900
    },
    {
      "epoch": 0.16375322389159536,
      "grad_norm": 0.8760257959365845,
      "learning_rate": 9.719993266371136e-06,
      "loss": 1.7386,
      "step": 1000
    },
    {
      "epoch": 0.16375322389159536,
      "eval_loss": 1.6945217847824097,
      "eval_runtime": 301.2144,
      "eval_samples_per_second": 20.862,
      "eval_steps_per_second": 5.216,
      "step": 1000
    },
    {
      "epoch": 0.1801285462807549,
      "grad_norm": 1.5598279237747192,
      "learning_rate": 9.663879692497617e-06,
      "loss": 1.6512,
      "step": 1100
    },
    {
      "epoch": 0.19650386866991443,
      "grad_norm": 2.953821897506714,
      "learning_rate": 9.607766118624096e-06,
      "loss": 1.3048,
      "step": 1200
    },
    {
      "epoch": 0.21287919105907396,
      "grad_norm": 0.3806343972682953,
      "learning_rate": 9.551652544750576e-06,
      "loss": 0.8876,
      "step": 1300
    },
    {
      "epoch": 0.2292545134482335,
      "grad_norm": 0.3364056348800659,
      "learning_rate": 9.495538970877057e-06,
      "loss": 0.8343,
      "step": 1400
    },
    {
      "epoch": 0.24562983583739306,
      "grad_norm": 0.05486298352479935,
      "learning_rate": 9.439425397003536e-06,
      "loss": 0.8324,
      "step": 1500
    },
    {
      "epoch": 0.24562983583739306,
      "eval_loss": 0.8253651857376099,
      "eval_runtime": 300.1783,
      "eval_samples_per_second": 20.934,
      "eval_steps_per_second": 5.234,
      "step": 1500
    },
    {
      "epoch": 0.26200515822655257,
      "grad_norm": 0.053497329354286194,
      "learning_rate": 9.383311823130015e-06,
      "loss": 0.8337,
      "step": 1600
    },
    {
      "epoch": 0.27838048061571213,
      "grad_norm": 0.06568707525730133,
      "learning_rate": 9.327198249256496e-06,
      "loss": 0.8301,
      "step": 1700
    },
    {
      "epoch": 0.29475580300487164,
      "grad_norm": 0.05180298164486885,
      "learning_rate": 9.271084675382977e-06,
      "loss": 0.8303,
      "step": 1800
    },
    {
      "epoch": 0.3111311253940312,
      "grad_norm": 0.03239640220999718,
      "learning_rate": 9.214971101509456e-06,
      "loss": 0.8309,
      "step": 1900
    },
    {
      "epoch": 0.3275064477831907,
      "grad_norm": 0.266248494386673,
      "learning_rate": 9.158857527635936e-06,
      "loss": 0.8277,
      "step": 2000
    },
    {
      "epoch": 0.3275064477831907,
      "eval_loss": 0.8229460716247559,
      "eval_runtime": 302.5031,
      "eval_samples_per_second": 20.773,
      "eval_steps_per_second": 5.193,
      "step": 2000
    },
    {
      "epoch": 0.3438817701723503,
      "grad_norm": 0.029939137399196625,
      "learning_rate": 9.102743953762417e-06,
      "loss": 0.8311,
      "step": 2100
    },
    {
      "epoch": 0.3602570925615098,
      "grad_norm": 0.060879215598106384,
      "learning_rate": 9.046630379888896e-06,
      "loss": 0.8324,
      "step": 2200
    },
    {
      "epoch": 0.37663241495066935,
      "grad_norm": 0.0498020313680172,
      "learning_rate": 8.990516806015375e-06,
      "loss": 0.8312,
      "step": 2300
    },
    {
      "epoch": 0.39300773733982886,
      "grad_norm": 0.07226257771253586,
      "learning_rate": 8.934403232141856e-06,
      "loss": 0.8285,
      "step": 2400
    },
    {
      "epoch": 0.4093830597289884,
      "grad_norm": 0.06373552232980728,
      "learning_rate": 8.878289658268336e-06,
      "loss": 0.8291,
      "step": 2500
    },
    {
      "epoch": 0.4093830597289884,
      "eval_loss": 0.822475016117096,
      "eval_runtime": 299.8298,
      "eval_samples_per_second": 20.959,
      "eval_steps_per_second": 5.24,
      "step": 2500
    },
    {
      "epoch": 0.4257583821181479,
      "grad_norm": 0.03582610934972763,
      "learning_rate": 8.822176084394815e-06,
      "loss": 0.831,
      "step": 2600
    },
    {
      "epoch": 0.4421337045073075,
      "grad_norm": 0.06818649917840958,
      "learning_rate": 8.766062510521296e-06,
      "loss": 0.8316,
      "step": 2700
    },
    {
      "epoch": 0.458509026896467,
      "grad_norm": 0.009319822303950787,
      "learning_rate": 8.709948936647777e-06,
      "loss": 0.8309,
      "step": 2800
    },
    {
      "epoch": 0.47488434928562656,
      "grad_norm": 0.03159811720252037,
      "learning_rate": 8.653835362774256e-06,
      "loss": 0.8315,
      "step": 2900
    },
    {
      "epoch": 0.4912596716747861,
      "grad_norm": 0.006539409048855305,
      "learning_rate": 8.597721788900735e-06,
      "loss": 0.8315,
      "step": 3000
    },
    {
      "epoch": 0.4912596716747861,
      "eval_loss": 0.8222458958625793,
      "eval_runtime": 303.0409,
      "eval_samples_per_second": 20.736,
      "eval_steps_per_second": 5.184,
      "step": 3000
    },
    {
      "epoch": 0.5076349940639456,
      "grad_norm": 0.19553954899311066,
      "learning_rate": 8.541608215027216e-06,
      "loss": 0.8281,
      "step": 3100
    },
    {
      "epoch": 0.5240103164531051,
      "grad_norm": 0.014024917036294937,
      "learning_rate": 8.485494641153696e-06,
      "loss": 0.8281,
      "step": 3200
    },
    {
      "epoch": 0.5403856388422648,
      "grad_norm": 0.004463235381990671,
      "learning_rate": 8.429381067280175e-06,
      "loss": 0.83,
      "step": 3300
    },
    {
      "epoch": 0.5567609612314243,
      "grad_norm": 0.012740612030029297,
      "learning_rate": 8.373267493406656e-06,
      "loss": 0.8294,
      "step": 3400
    },
    {
      "epoch": 0.5731362836205838,
      "grad_norm": 0.00828036479651928,
      "learning_rate": 8.317153919533135e-06,
      "loss": 0.83,
      "step": 3500
    },
    {
      "epoch": 0.5731362836205838,
      "eval_loss": 0.8222886323928833,
      "eval_runtime": 299.1267,
      "eval_samples_per_second": 21.008,
      "eval_steps_per_second": 5.252,
      "step": 3500
    },
    {
      "epoch": 0.5895116060097433,
      "grad_norm": 0.01874815672636032,
      "learning_rate": 8.261040345659616e-06,
      "loss": 0.83,
      "step": 3600
    },
    {
      "epoch": 0.6058869283989029,
      "grad_norm": 0.031193669885396957,
      "learning_rate": 8.204926771786096e-06,
      "loss": 0.83,
      "step": 3700
    },
    {
      "epoch": 0.6222622507880624,
      "grad_norm": 0.005893650930374861,
      "learning_rate": 8.148813197912576e-06,
      "loss": 0.8293,
      "step": 3800
    },
    {
      "epoch": 0.6386375731772219,
      "grad_norm": 0.031839918345212936,
      "learning_rate": 8.092699624039056e-06,
      "loss": 0.83,
      "step": 3900
    },
    {
      "epoch": 0.6550128955663814,
      "grad_norm": 0.0029834986198693514,
      "learning_rate": 8.036586050165535e-06,
      "loss": 0.83,
      "step": 4000
    },
    {
      "epoch": 0.6550128955663814,
      "eval_loss": 0.8220682740211487,
      "eval_runtime": 298.3421,
      "eval_samples_per_second": 21.063,
      "eval_steps_per_second": 5.266,
      "step": 4000
    },
    {
      "epoch": 0.671388217955541,
      "grad_norm": 0.005363864358514547,
      "learning_rate": 7.980472476292016e-06,
      "loss": 0.83,
      "step": 4100
    },
    {
      "epoch": 0.6877635403447006,
      "grad_norm": 0.001652283826842904,
      "learning_rate": 7.924358902418495e-06,
      "loss": 0.8319,
      "step": 4200
    },
    {
      "epoch": 0.7041388627338601,
      "grad_norm": 0.009365876205265522,
      "learning_rate": 7.868245328544976e-06,
      "loss": 0.8306,
      "step": 4300
    },
    {
      "epoch": 0.7205141851230196,
      "grad_norm": 0.001902089104987681,
      "learning_rate": 7.812131754671456e-06,
      "loss": 0.8286,
      "step": 4400
    },
    {
      "epoch": 0.7368895075121792,
      "grad_norm": 0.022344375029206276,
      "learning_rate": 7.756018180797935e-06,
      "loss": 0.8293,
      "step": 4500
    },
    {
      "epoch": 0.7368895075121792,
      "eval_loss": 0.8220012784004211,
      "eval_runtime": 301.3949,
      "eval_samples_per_second": 20.85,
      "eval_steps_per_second": 5.212,
      "step": 4500
    },
    {
      "epoch": 0.7532648299013387,
      "grad_norm": 0.005124324932694435,
      "learning_rate": 7.699904606924416e-06,
      "loss": 0.8319,
      "step": 4600
    },
    {
      "epoch": 0.7696401522904982,
      "grad_norm": 0.014103109948337078,
      "learning_rate": 7.643791033050895e-06,
      "loss": 0.8279,
      "step": 4700
    },
    {
      "epoch": 0.7860154746796577,
      "grad_norm": 0.002848078263923526,
      "learning_rate": 7.587677459177376e-06,
      "loss": 0.8279,
      "step": 4800
    },
    {
      "epoch": 0.8023907970688173,
      "grad_norm": 0.06726302951574326,
      "learning_rate": 7.5315638853038555e-06,
      "loss": 0.8312,
      "step": 4900
    },
    {
      "epoch": 0.8187661194579768,
      "grad_norm": 0.0027182719204574823,
      "learning_rate": 7.475450311430336e-06,
      "loss": 0.8292,
      "step": 5000
    },
    {
      "epoch": 0.8187661194579768,
      "eval_loss": 0.8219420909881592,
      "eval_runtime": 315.9369,
      "eval_samples_per_second": 19.89,
      "eval_steps_per_second": 4.973,
      "step": 5000
    },
    {
      "epoch": 0.8351414418471363,
      "grad_norm": 0.0021715264301747084,
      "learning_rate": 7.419336737556816e-06,
      "loss": 0.8312,
      "step": 5100
    },
    {
      "epoch": 0.8515167642362959,
      "grad_norm": 0.0016673282952979207,
      "learning_rate": 7.363223163683295e-06,
      "loss": 0.8299,
      "step": 5200
    },
    {
      "epoch": 0.8678920866254555,
      "grad_norm": 0.023046547546982765,
      "learning_rate": 7.307109589809775e-06,
      "loss": 0.8299,
      "step": 5300
    },
    {
      "epoch": 0.884267409014615,
      "grad_norm": 0.006409020163118839,
      "learning_rate": 7.250996015936256e-06,
      "loss": 0.8292,
      "step": 5400
    },
    {
      "epoch": 0.9006427314037745,
      "grad_norm": 0.0009078496368601918,
      "learning_rate": 7.194882442062736e-06,
      "loss": 0.8312,
      "step": 5500
    },
    {
      "epoch": 0.9006427314037745,
      "eval_loss": 0.8219311833381653,
      "eval_runtime": 314.084,
      "eval_samples_per_second": 20.007,
      "eval_steps_per_second": 5.002,
      "step": 5500
    },
    {
      "epoch": 0.917018053792934,
      "grad_norm": 0.009478195570409298,
      "learning_rate": 7.138768868189216e-06,
      "loss": 0.8305,
      "step": 5600
    },
    {
      "epoch": 0.9333933761820936,
      "grad_norm": 0.00248395255766809,
      "learning_rate": 7.082655294315696e-06,
      "loss": 0.8279,
      "step": 5700
    },
    {
      "epoch": 0.9497686985712531,
      "grad_norm": 0.0013986347476020455,
      "learning_rate": 7.026541720442176e-06,
      "loss": 0.8298,
      "step": 5800
    },
    {
      "epoch": 0.9661440209604126,
      "grad_norm": 0.006737333722412586,
      "learning_rate": 6.970428146568655e-06,
      "loss": 0.8312,
      "step": 5900
    },
    {
      "epoch": 0.9825193433495722,
      "grad_norm": 0.0024045519530773163,
      "learning_rate": 6.914314572695135e-06,
      "loss": 0.8292,
      "step": 6000
    },
    {
      "epoch": 0.9825193433495722,
      "eval_loss": 0.8218609690666199,
      "eval_runtime": 314.0107,
      "eval_samples_per_second": 20.012,
      "eval_steps_per_second": 5.003,
      "step": 6000
    },
    {
      "epoch": 0.9988946657387318,
      "grad_norm": 0.004697046242654324,
      "learning_rate": 6.8582009988216155e-06,
      "loss": 0.8305,
      "step": 6100
    },
    {
      "epoch": 1.0152290498219183,
      "grad_norm": 0.0024411960039287806,
      "learning_rate": 6.802087424948095e-06,
      "loss": 0.8264,
      "step": 6200
    },
    {
      "epoch": 1.031604372211078,
      "grad_norm": 0.0054432423785328865,
      "learning_rate": 6.745973851074576e-06,
      "loss": 0.8279,
      "step": 6300
    },
    {
      "epoch": 1.0479796946002375,
      "grad_norm": 0.0013853107811883092,
      "learning_rate": 6.689860277201056e-06,
      "loss": 0.8305,
      "step": 6400
    },
    {
      "epoch": 1.064355016989397,
      "grad_norm": 0.001337956404313445,
      "learning_rate": 6.633746703327536e-06,
      "loss": 0.8285,
      "step": 6500
    },
    {
      "epoch": 1.064355016989397,
      "eval_loss": 0.8218509554862976,
      "eval_runtime": 318.5588,
      "eval_samples_per_second": 19.726,
      "eval_steps_per_second": 4.932,
      "step": 6500
    },
    {
      "epoch": 1.0807303393785566,
      "grad_norm": 0.007861134596168995,
      "learning_rate": 6.577633129454015e-06,
      "loss": 0.8285,
      "step": 6600
    },
    {
      "epoch": 1.097105661767716,
      "grad_norm": 0.009629335254430771,
      "learning_rate": 6.5215195555804954e-06,
      "loss": 0.8298,
      "step": 6700
    },
    {
      "epoch": 1.1134809841568756,
      "grad_norm": 0.004910562187433243,
      "learning_rate": 6.465405981706976e-06,
      "loss": 0.8298,
      "step": 6800
    },
    {
      "epoch": 1.1298563065460352,
      "grad_norm": 0.0008393183816224337,
      "learning_rate": 6.409292407833455e-06,
      "loss": 0.8291,
      "step": 6900
    },
    {
      "epoch": 1.1462316289351946,
      "grad_norm": 0.0008628622745163739,
      "learning_rate": 6.353178833959935e-06,
      "loss": 0.8305,
      "step": 7000
    },
    {
      "epoch": 1.1462316289351946,
      "eval_loss": 0.8218297362327576,
      "eval_runtime": 319.1573,
      "eval_samples_per_second": 19.689,
      "eval_steps_per_second": 4.922,
      "step": 7000
    },
    {
      "epoch": 1.1626069513243542,
      "grad_norm": 0.0005091606290079653,
      "learning_rate": 6.297065260086416e-06,
      "loss": 0.8298,
      "step": 7100
    },
    {
      "epoch": 1.1789822737135138,
      "grad_norm": 0.0036153392866253853,
      "learning_rate": 6.240951686212895e-06,
      "loss": 0.8311,
      "step": 7200
    },
    {
      "epoch": 1.1953575961026732,
      "grad_norm": 0.0028815686237066984,
      "learning_rate": 6.1848381123393754e-06,
      "loss": 0.8311,
      "step": 7300
    },
    {
      "epoch": 1.2117329184918328,
      "grad_norm": 0.001295430469326675,
      "learning_rate": 6.1287245384658556e-06,
      "loss": 0.8318,
      "step": 7400
    },
    {
      "epoch": 1.2281082408809922,
      "grad_norm": 0.001971970545127988,
      "learning_rate": 6.072610964592336e-06,
      "loss": 0.8278,
      "step": 7500
    },
    {
      "epoch": 1.2281082408809922,
      "eval_loss": 0.8218227028846741,
      "eval_runtime": 318.2573,
      "eval_samples_per_second": 19.745,
      "eval_steps_per_second": 4.936,
      "step": 7500
    },
    {
      "epoch": 1.2444835632701519,
      "grad_norm": 0.0006060234736651182,
      "learning_rate": 6.016497390718815e-06,
      "loss": 0.8278,
      "step": 7600
    },
    {
      "epoch": 1.2608588856593115,
      "grad_norm": 0.008116974495351315,
      "learning_rate": 5.960383816845295e-06,
      "loss": 0.8298,
      "step": 7700
    },
    {
      "epoch": 1.2772342080484709,
      "grad_norm": 0.0010780615266412497,
      "learning_rate": 5.904270242971776e-06,
      "loss": 0.8278,
      "step": 7800
    },
    {
      "epoch": 1.2936095304376305,
      "grad_norm": 0.001782559440471232,
      "learning_rate": 5.8481566690982546e-06,
      "loss": 0.8298,
      "step": 7900
    },
    {
      "epoch": 1.3099848528267901,
      "grad_norm": 0.0006814342341385782,
      "learning_rate": 5.7920430952247356e-06,
      "loss": 0.8278,
      "step": 8000
    },
    {
      "epoch": 1.3099848528267901,
      "eval_loss": 0.8218786716461182,
      "eval_runtime": 315.2773,
      "eval_samples_per_second": 19.932,
      "eval_steps_per_second": 4.983,
      "step": 8000
    },
    {
      "epoch": 1.3263601752159495,
      "grad_norm": 0.0012179907644167542,
      "learning_rate": 5.735929521351216e-06,
      "loss": 0.8265,
      "step": 8100
    },
    {
      "epoch": 1.3427354976051091,
      "grad_norm": 0.00031189664150588214,
      "learning_rate": 5.679815947477695e-06,
      "loss": 0.8298,
      "step": 8200
    },
    {
      "epoch": 1.3591108199942687,
      "grad_norm": 0.015849322080612183,
      "learning_rate": 5.623702373604175e-06,
      "loss": 0.832,
      "step": 8300
    },
    {
      "epoch": 1.3754861423834281,
      "grad_norm": 0.0012404611334204674,
      "learning_rate": 5.567588799730655e-06,
      "loss": 0.8298,
      "step": 8400
    },
    {
      "epoch": 1.3918614647725878,
      "grad_norm": 0.0012671248987317085,
      "learning_rate": 5.511475225857135e-06,
      "loss": 0.8278,
      "step": 8500
    },
    {
      "epoch": 1.3918614647725878,
      "eval_loss": 0.8218137621879578,
      "eval_runtime": 316.4636,
      "eval_samples_per_second": 19.857,
      "eval_steps_per_second": 4.964,
      "step": 8500
    },
    {
      "epoch": 1.4082367871617474,
      "grad_norm": 0.0003611373249441385,
      "learning_rate": 5.455361651983615e-06,
      "loss": 0.8285,
      "step": 8600
    },
    {
      "epoch": 1.4246121095509068,
      "grad_norm": 0.0003464473120402545,
      "learning_rate": 5.399248078110096e-06,
      "loss": 0.8304,
      "step": 8700
    },
    {
      "epoch": 1.4409874319400664,
      "grad_norm": 0.00944097526371479,
      "learning_rate": 5.343134504236576e-06,
      "loss": 0.8318,
      "step": 8800
    },
    {
      "epoch": 1.4573627543292258,
      "grad_norm": 0.0006608827388845384,
      "learning_rate": 5.287020930363055e-06,
      "loss": 0.8291,
      "step": 8900
    },
    {
      "epoch": 1.4737380767183854,
      "grad_norm": 0.0025951815769076347,
      "learning_rate": 5.230907356489535e-06,
      "loss": 0.8311,
      "step": 9000
    },
    {
      "epoch": 1.4737380767183854,
      "eval_loss": 0.8218047022819519,
      "eval_runtime": 321.0565,
      "eval_samples_per_second": 19.573,
      "eval_steps_per_second": 4.893,
      "step": 9000
    },
    {
      "epoch": 1.4901133991075448,
      "grad_norm": 0.0002894066565204412,
      "learning_rate": 5.174793782616015e-06,
      "loss": 0.8311,
      "step": 9100
    },
    {
      "epoch": 1.5064887214967044,
      "grad_norm": 0.00039935321547091007,
      "learning_rate": 5.118680208742495e-06,
      "loss": 0.8278,
      "step": 9200
    },
    {
      "epoch": 1.522864043885864,
      "grad_norm": 0.00036787500721402466,
      "learning_rate": 5.062566634868975e-06,
      "loss": 0.8278,
      "step": 9300
    },
    {
      "epoch": 1.5392393662750234,
      "grad_norm": 0.0007021534256637096,
      "learning_rate": 5.006453060995455e-06,
      "loss": 0.8304,
      "step": 9400
    },
    {
      "epoch": 1.555614688664183,
      "grad_norm": 0.001030756626278162,
      "learning_rate": 4.950339487121935e-06,
      "loss": 0.8285,
      "step": 9500
    },
    {
      "epoch": 1.555614688664183,
      "eval_loss": 0.8218021392822266,
      "eval_runtime": 316.941,
      "eval_samples_per_second": 19.827,
      "eval_steps_per_second": 4.957,
      "step": 9500
    },
    {
      "epoch": 1.5719900110533427,
      "grad_norm": 0.0004495041212067008,
      "learning_rate": 4.894225913248415e-06,
      "loss": 0.8298,
      "step": 9600
    },
    {
      "epoch": 1.588365333442502,
      "grad_norm": 0.0001493683666922152,
      "learning_rate": 4.838112339374895e-06,
      "loss": 0.8304,
      "step": 9700
    },
    {
      "epoch": 1.6047406558316617,
      "grad_norm": 0.0008183543104678392,
      "learning_rate": 4.781998765501375e-06,
      "loss": 0.8298,
      "step": 9800
    },
    {
      "epoch": 1.6211159782208213,
      "grad_norm": 0.0004477571346797049,
      "learning_rate": 4.725885191627856e-06,
      "loss": 0.8285,
      "step": 9900
    },
    {
      "epoch": 1.6374913006099807,
      "grad_norm": 0.0004563517577480525,
      "learning_rate": 4.669771617754335e-06,
      "loss": 0.8298,
      "step": 10000
    },
    {
      "epoch": 1.6374913006099807,
      "eval_loss": 0.821800708770752,
      "eval_runtime": 313.7521,
      "eval_samples_per_second": 20.029,
      "eval_steps_per_second": 5.007,
      "step": 10000
    },
    {
      "epoch": 1.6538666229991403,
      "grad_norm": 0.001772503019310534,
      "learning_rate": 4.613658043880815e-06,
      "loss": 0.8298,
      "step": 10100
    },
    {
      "epoch": 1.6702419453883,
      "grad_norm": 0.0008477138471789658,
      "learning_rate": 4.557544470007295e-06,
      "loss": 0.8298,
      "step": 10200
    },
    {
      "epoch": 1.6866172677774594,
      "grad_norm": 0.0002049634204013273,
      "learning_rate": 4.5014308961337745e-06,
      "loss": 0.8311,
      "step": 10300
    },
    {
      "epoch": 1.7029925901666187,
      "grad_norm": 0.0008285124786198139,
      "learning_rate": 4.4453173222602555e-06,
      "loss": 0.8304,
      "step": 10400
    },
    {
      "epoch": 1.7193679125557786,
      "grad_norm": 0.0006207299302332103,
      "learning_rate": 4.389203748386735e-06,
      "loss": 0.8291,
      "step": 10500
    },
    {
      "epoch": 1.7193679125557786,
      "eval_loss": 0.8217986226081848,
      "eval_runtime": 313.9208,
      "eval_samples_per_second": 20.018,
      "eval_steps_per_second": 5.004,
      "step": 10500
    },
    {
      "epoch": 1.735743234944938,
      "grad_norm": 0.0005782520747743547,
      "learning_rate": 4.333090174513215e-06,
      "loss": 0.8291,
      "step": 10600
    },
    {
      "epoch": 1.7521185573340974,
      "grad_norm": 0.0004130462766624987,
      "learning_rate": 4.276976600639695e-06,
      "loss": 0.8311,
      "step": 10700
    },
    {
      "epoch": 1.768493879723257,
      "grad_norm": 0.0001718932471703738,
      "learning_rate": 4.220863026766175e-06,
      "loss": 0.8285,
      "step": 10800
    },
    {
      "epoch": 1.7848692021124166,
      "grad_norm": 0.00246775452978909,
      "learning_rate": 4.164749452892655e-06,
      "loss": 0.8271,
      "step": 10900
    },
    {
      "epoch": 1.801244524501576,
      "grad_norm": 0.0004606322036124766,
      "learning_rate": 4.108635879019135e-06,
      "loss": 0.8311,
      "step": 11000
    },
    {
      "epoch": 1.801244524501576,
      "eval_loss": 0.8217973113059998,
      "eval_runtime": 312.0533,
      "eval_samples_per_second": 20.138,
      "eval_steps_per_second": 5.034,
      "step": 11000
    },
    {
      "epoch": 1.8176198468907356,
      "grad_norm": 0.0001797248114598915,
      "learning_rate": 4.052522305145616e-06,
      "loss": 0.8291,
      "step": 11100
    },
    {
      "epoch": 1.8339951692798953,
      "grad_norm": 0.0005447170115076005,
      "learning_rate": 3.996408731272095e-06,
      "loss": 0.8311,
      "step": 11200
    },
    {
      "epoch": 1.8503704916690547,
      "grad_norm": 0.0009862063452601433,
      "learning_rate": 3.940295157398575e-06,
      "loss": 0.8298,
      "step": 11300
    },
    {
      "epoch": 1.8667458140582143,
      "grad_norm": 0.0009633052977733314,
      "learning_rate": 3.884181583525055e-06,
      "loss": 0.8298,
      "step": 11400
    },
    {
      "epoch": 1.8831211364473739,
      "grad_norm": 0.00029721518512815237,
      "learning_rate": 3.8280680096515345e-06,
      "loss": 0.8298,
      "step": 11500
    },
    {
      "epoch": 1.8831211364473739,
      "eval_loss": 0.8217958211898804,
      "eval_runtime": 315.6094,
      "eval_samples_per_second": 19.911,
      "eval_steps_per_second": 4.978,
      "step": 11500
    },
    {
      "epoch": 1.8994964588365333,
      "grad_norm": 0.000366516673238948,
      "learning_rate": 3.771954435778015e-06,
      "loss": 0.8311,
      "step": 11600
    },
    {
      "epoch": 1.915871781225693,
      "grad_norm": 0.00029023675597272813,
      "learning_rate": 3.715840861904495e-06,
      "loss": 0.8304,
      "step": 11700
    },
    {
      "epoch": 1.9322471036148525,
      "grad_norm": 0.0002658690791577101,
      "learning_rate": 3.659727288030975e-06,
      "loss": 0.8271,
      "step": 11800
    },
    {
      "epoch": 1.948622426004012,
      "grad_norm": 0.00031580025097355247,
      "learning_rate": 3.603613714157455e-06,
      "loss": 0.8304,
      "step": 11900
    },
    {
      "epoch": 1.9649977483931715,
      "grad_norm": 0.000985357561148703,
      "learning_rate": 3.5475001402839348e-06,
      "loss": 0.8304,
      "step": 12000
    },
    {
      "epoch": 1.9649977483931715,
      "eval_loss": 0.8217991590499878,
      "eval_runtime": 304.13,
      "eval_samples_per_second": 20.662,
      "eval_steps_per_second": 5.166,
      "step": 12000
    },
    {
      "epoch": 1.9813730707823312,
      "grad_norm": 0.0002607367350719869,
      "learning_rate": 3.4913865664104153e-06,
      "loss": 0.8291,
      "step": 12100
    },
    {
      "epoch": 1.9977483931714906,
      "grad_norm": 0.00038332430995069444,
      "learning_rate": 3.435272992536895e-06,
      "loss": 0.8304,
      "step": 12200
    },
    {
      "epoch": 2.014082777254677,
      "grad_norm": 0.00030077449628151953,
      "learning_rate": 3.3791594186633748e-06,
      "loss": 0.8264,
      "step": 12300
    },
    {
      "epoch": 2.0304580996438366,
      "grad_norm": 0.0005825704429298639,
      "learning_rate": 3.323045844789855e-06,
      "loss": 0.8278,
      "step": 12400
    },
    {
      "epoch": 2.0468334220329965,
      "grad_norm": 0.00014509091852232814,
      "learning_rate": 3.2669322709163346e-06,
      "loss": 0.8304,
      "step": 12500
    },
    {
      "epoch": 2.0468334220329965,
      "eval_loss": 0.8217933773994446,
      "eval_runtime": 308.4933,
      "eval_samples_per_second": 20.37,
      "eval_steps_per_second": 5.092,
      "step": 12500
    },
    {
      "epoch": 2.063208744422156,
      "grad_norm": 0.00010472997382748872,
      "learning_rate": 3.210818697042815e-06,
      "loss": 0.8298,
      "step": 12600
    },
    {
      "epoch": 2.0795840668113152,
      "grad_norm": 8.630101365270093e-05,
      "learning_rate": 3.154705123169295e-06,
      "loss": 0.8271,
      "step": 12700
    },
    {
      "epoch": 2.095959389200475,
      "grad_norm": 4.699288911069743e-05,
      "learning_rate": 3.0985915492957746e-06,
      "loss": 0.8298,
      "step": 12800
    },
    {
      "epoch": 2.1123347115896345,
      "grad_norm": 0.00014284094504546374,
      "learning_rate": 3.042477975422255e-06,
      "loss": 0.8304,
      "step": 12900
    },
    {
      "epoch": 2.128710033978794,
      "grad_norm": 0.00014472304610535502,
      "learning_rate": 2.986364401548735e-06,
      "loss": 0.8291,
      "step": 13000
    },
    {
      "epoch": 2.128710033978794,
      "eval_loss": 0.821792721748352,
      "eval_runtime": 303.4976,
      "eval_samples_per_second": 20.705,
      "eval_steps_per_second": 5.176,
      "step": 13000
    },
    {
      "epoch": 2.1450853563679537,
      "grad_norm": 0.00018965550407301635,
      "learning_rate": 2.930250827675215e-06,
      "loss": 0.8298,
      "step": 13100
    },
    {
      "epoch": 2.161460678757113,
      "grad_norm": 0.0002174352266592905,
      "learning_rate": 2.8741372538016947e-06,
      "loss": 0.8298,
      "step": 13200
    },
    {
      "epoch": 2.1778360011462725,
      "grad_norm": 0.0061288452707231045,
      "learning_rate": 2.8180236799281745e-06,
      "loss": 0.8311,
      "step": 13300
    },
    {
      "epoch": 2.194211323535432,
      "grad_norm": 0.00012460794823709875,
      "learning_rate": 2.761910106054655e-06,
      "loss": 0.8311,
      "step": 13400
    },
    {
      "epoch": 2.2105866459245918,
      "grad_norm": 0.0001411555422237143,
      "learning_rate": 2.7057965321811347e-06,
      "loss": 0.8318,
      "step": 13500
    },
    {
      "epoch": 2.2105866459245918,
      "eval_loss": 0.8217921257019043,
      "eval_runtime": 303.8576,
      "eval_samples_per_second": 20.681,
      "eval_steps_per_second": 5.17,
      "step": 13500
    },
    {
      "epoch": 2.226961968313751,
      "grad_norm": 0.00018130472744815052,
      "learning_rate": 2.649682958307615e-06,
      "loss": 0.8285,
      "step": 13600
    },
    {
      "epoch": 2.2433372907029105,
      "grad_norm": 5.217277066549286e-05,
      "learning_rate": 2.5935693844340946e-06,
      "loss": 0.8271,
      "step": 13700
    },
    {
      "epoch": 2.2597126130920704,
      "grad_norm": 0.0002766901452559978,
      "learning_rate": 2.5374558105605747e-06,
      "loss": 0.8298,
      "step": 13800
    },
    {
      "epoch": 2.27608793548123,
      "grad_norm": 9.030773071572185e-05,
      "learning_rate": 2.481342236687055e-06,
      "loss": 0.8291,
      "step": 13900
    },
    {
      "epoch": 2.292463257870389,
      "grad_norm": 0.0003487209905870259,
      "learning_rate": 2.425228662813535e-06,
      "loss": 0.8284,
      "step": 14000
    },
    {
      "epoch": 2.292463257870389,
      "eval_loss": 0.8217915892601013,
      "eval_runtime": 306.2172,
      "eval_samples_per_second": 20.521,
      "eval_steps_per_second": 5.13,
      "step": 14000
    },
    {
      "epoch": 2.308838580259549,
      "grad_norm": 0.00013535488687921315,
      "learning_rate": 2.3691150889400147e-06,
      "loss": 0.8284,
      "step": 14100
    },
    {
      "epoch": 2.3252139026487084,
      "grad_norm": 0.00026093717315234244,
      "learning_rate": 2.313001515066495e-06,
      "loss": 0.8265,
      "step": 14200
    },
    {
      "epoch": 2.341589225037868,
      "grad_norm": 0.00013835141726303846,
      "learning_rate": 2.2568879411929746e-06,
      "loss": 0.8298,
      "step": 14300
    },
    {
      "epoch": 2.3579645474270277,
      "grad_norm": 0.0002484353317413479,
      "learning_rate": 2.2007743673194547e-06,
      "loss": 0.8318,
      "step": 14400
    },
    {
      "epoch": 2.374339869816187,
      "grad_norm": 5.876936120330356e-05,
      "learning_rate": 2.144660793445935e-06,
      "loss": 0.8291,
      "step": 14500
    },
    {
      "epoch": 2.374339869816187,
      "eval_loss": 0.8217912316322327,
      "eval_runtime": 301.4702,
      "eval_samples_per_second": 20.845,
      "eval_steps_per_second": 5.211,
      "step": 14500
    },
    {
      "epoch": 2.3907151922053465,
      "grad_norm": 0.00022064420045353472,
      "learning_rate": 2.0885472195724146e-06,
      "loss": 0.8284,
      "step": 14600
    },
    {
      "epoch": 2.407090514594506,
      "grad_norm": 9.785553265828639e-05,
      "learning_rate": 2.0324336456988947e-06,
      "loss": 0.8291,
      "step": 14700
    },
    {
      "epoch": 2.4234658369836657,
      "grad_norm": 2.934691838163417e-05,
      "learning_rate": 1.976320071825375e-06,
      "loss": 0.8298,
      "step": 14800
    },
    {
      "epoch": 2.439841159372825,
      "grad_norm": 0.00019518188491929322,
      "learning_rate": 1.9202064979518546e-06,
      "loss": 0.8311,
      "step": 14900
    },
    {
      "epoch": 2.4562164817619845,
      "grad_norm": 0.0010149965528398752,
      "learning_rate": 1.864092924078335e-06,
      "loss": 0.8291,
      "step": 15000
    },
    {
      "epoch": 2.4562164817619845,
      "eval_loss": 0.821790874004364,
      "eval_runtime": 300.5076,
      "eval_samples_per_second": 20.911,
      "eval_steps_per_second": 5.228,
      "step": 15000
    },
    {
      "epoch": 2.4725918041511443,
      "grad_norm": 2.5331777578685433e-05,
      "learning_rate": 1.8079793502048146e-06,
      "loss": 0.8311,
      "step": 15100
    },
    {
      "epoch": 2.4889671265403037,
      "grad_norm": 0.00039474281948059797,
      "learning_rate": 1.7518657763312946e-06,
      "loss": 0.8311,
      "step": 15200
    },
    {
      "epoch": 2.505342448929463,
      "grad_norm": 0.00011110291961813346,
      "learning_rate": 1.6957522024577747e-06,
      "loss": 0.8278,
      "step": 15300
    },
    {
      "epoch": 2.521717771318623,
      "grad_norm": 0.0001548528962302953,
      "learning_rate": 1.6396386285842546e-06,
      "loss": 0.8278,
      "step": 15400
    },
    {
      "epoch": 2.5380930937077824,
      "grad_norm": 0.00011255558638367802,
      "learning_rate": 1.5835250547107348e-06,
      "loss": 0.8304,
      "step": 15500
    },
    {
      "epoch": 2.5380930937077824,
      "eval_loss": 0.821790874004364,
      "eval_runtime": 301.5384,
      "eval_samples_per_second": 20.84,
      "eval_steps_per_second": 5.21,
      "step": 15500
    },
    {
      "epoch": 2.5544684160969418,
      "grad_norm": 0.0002626588102430105,
      "learning_rate": 1.5274114808372145e-06,
      "loss": 0.8284,
      "step": 15600
    },
    {
      "epoch": 2.5708437384861016,
      "grad_norm": 6.61418671370484e-05,
      "learning_rate": 1.4712979069636946e-06,
      "loss": 0.8304,
      "step": 15700
    },
    {
      "epoch": 2.587219060875261,
      "grad_norm": 8.634060941403732e-05,
      "learning_rate": 1.4151843330901745e-06,
      "loss": 0.8298,
      "step": 15800
    },
    {
      "epoch": 2.6035943832644204,
      "grad_norm": 4.92822437081486e-05,
      "learning_rate": 1.3590707592166547e-06,
      "loss": 0.8298,
      "step": 15900
    },
    {
      "epoch": 2.6199697056535802,
      "grad_norm": 0.00015397940296679735,
      "learning_rate": 1.3029571853431346e-06,
      "loss": 0.8284,
      "step": 16000
    },
    {
      "epoch": 2.6199697056535802,
      "eval_loss": 0.8217902183532715,
      "eval_runtime": 301.8839,
      "eval_samples_per_second": 20.816,
      "eval_steps_per_second": 5.204,
      "step": 16000
    },
    {
      "epoch": 2.6363450280427396,
      "grad_norm": 0.00010743704478954896,
      "learning_rate": 1.2468436114696145e-06,
      "loss": 0.8304,
      "step": 16100
    },
    {
      "epoch": 2.652720350431899,
      "grad_norm": 6.309305172180757e-05,
      "learning_rate": 1.1907300375960947e-06,
      "loss": 0.8291,
      "step": 16200
    },
    {
      "epoch": 2.669095672821059,
      "grad_norm": 0.0001266508043045178,
      "learning_rate": 1.1346164637225746e-06,
      "loss": 0.8304,
      "step": 16300
    },
    {
      "epoch": 2.6854709952102183,
      "grad_norm": 0.00015778282249812037,
      "learning_rate": 1.0785028898490545e-06,
      "loss": 0.8304,
      "step": 16400
    },
    {
      "epoch": 2.7018463175993777,
      "grad_norm": 3.74947558157146e-05,
      "learning_rate": 1.0223893159755345e-06,
      "loss": 0.8304,
      "step": 16500
    },
    {
      "epoch": 2.7018463175993777,
      "eval_loss": 0.8217902183532715,
      "eval_runtime": 302.1602,
      "eval_samples_per_second": 20.797,
      "eval_steps_per_second": 5.199,
      "step": 16500
    },
    {
      "epoch": 2.7182216399885375,
      "grad_norm": 0.00017388742708135396,
      "learning_rate": 9.662757421020146e-07,
      "loss": 0.8291,
      "step": 16600
    },
    {
      "epoch": 2.734596962377697,
      "grad_norm": 1.731828524498269e-05,
      "learning_rate": 9.101621682284946e-07,
      "loss": 0.8291,
      "step": 16700
    },
    {
      "epoch": 2.7509722847668563,
      "grad_norm": 0.00016764095926191658,
      "learning_rate": 8.540485943549746e-07,
      "loss": 0.8311,
      "step": 16800
    },
    {
      "epoch": 2.767347607156016,
      "grad_norm": 2.3113978386390954e-05,
      "learning_rate": 7.979350204814546e-07,
      "loss": 0.8284,
      "step": 16900
    },
    {
      "epoch": 2.7837229295451755,
      "grad_norm": 5.654255437548272e-05,
      "learning_rate": 7.418214466079344e-07,
      "loss": 0.8271,
      "step": 17000
    },
    {
      "epoch": 2.7837229295451755,
      "eval_loss": 0.8217898607254028,
      "eval_runtime": 301.4264,
      "eval_samples_per_second": 20.848,
      "eval_steps_per_second": 5.212,
      "step": 17000
    },
    {
      "epoch": 2.800098251934335,
      "grad_norm": 5.284810686134733e-05,
      "learning_rate": 6.857078727344145e-07,
      "loss": 0.8311,
      "step": 17100
    },
    {
      "epoch": 2.8164735743234948,
      "grad_norm": 0.00021930474031250924,
      "learning_rate": 6.295942988608946e-07,
      "loss": 0.8291,
      "step": 17200
    },
    {
      "epoch": 2.832848896712654,
      "grad_norm": 4.13958405260928e-05,
      "learning_rate": 5.734807249873745e-07,
      "loss": 0.8317,
      "step": 17300
    },
    {
      "epoch": 2.8492242191018136,
      "grad_norm": 0.00016031929408200085,
      "learning_rate": 5.173671511138545e-07,
      "loss": 0.8298,
      "step": 17400
    },
    {
      "epoch": 2.865599541490973,
      "grad_norm": 5.6283479352714494e-05,
      "learning_rate": 4.6125357724033446e-07,
      "loss": 0.8291,
      "step": 17500
    },
    {
      "epoch": 2.865599541490973,
      "eval_loss": 0.8217906951904297,
      "eval_runtime": 302.1709,
      "eval_samples_per_second": 20.796,
      "eval_steps_per_second": 5.199,
      "step": 17500
    },
    {
      "epoch": 2.881974863880133,
      "grad_norm": 6.28381603746675e-05,
      "learning_rate": 4.0514000336681444e-07,
      "loss": 0.8298,
      "step": 17600
    },
    {
      "epoch": 2.898350186269292,
      "grad_norm": 0.002201444935053587,
      "learning_rate": 3.490264294932945e-07,
      "loss": 0.8311,
      "step": 17700
    },
    {
      "epoch": 2.9147255086584516,
      "grad_norm": 7.09879823261872e-05,
      "learning_rate": 2.9291285561977446e-07,
      "loss": 0.8304,
      "step": 17800
    },
    {
      "epoch": 2.931100831047611,
      "grad_norm": 3.7859445001231506e-05,
      "learning_rate": 2.3679928174625444e-07,
      "loss": 0.8278,
      "step": 17900
    },
    {
      "epoch": 2.947476153436771,
      "grad_norm": 0.00014170596841722727,
      "learning_rate": 1.8068570787273442e-07,
      "loss": 0.8298,
      "step": 18000
    },
    {
      "epoch": 2.947476153436771,
      "eval_loss": 0.8217898011207581,
      "eval_runtime": 300.735,
      "eval_samples_per_second": 20.895,
      "eval_steps_per_second": 5.224,
      "step": 18000
    }
  ],
  "logging_steps": 100,
  "max_steps": 18321,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
